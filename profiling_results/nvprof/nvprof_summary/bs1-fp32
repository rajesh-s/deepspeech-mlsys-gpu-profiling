==47590== NVPROF is profiling process 47590, command: python train.py +configs=librispeech
==47590== Warning: Profiling results might be incorrect with current version of nvcc compiler used to compile cuda app. Compile with nvcc compiler 9.0 or later version to get correct profiling results. Ignore this warning if code is already compiled with the recommended nvcc version 
==47590== Profiling application: python train.py +configs=librispeech
==47590== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   68.90%  6.16521s    122350  50.389us  25.023us  165.50us  void gemv2N_kernel<int, int, __half, __half, __half, float, int=128, int=4, int=4, int=4, int=1, bool=0, cublasGemvParams<cublasGemvTensorStridedBatched<__half const >, cublasGemvTensorStridedBatched<__half const >, cublasGemvTensorStridedBatched<__half>, float>>(__half const )
                    8.80%  787.22ms      1802  436.86us  14.496us  571.22us  maxwell_fp16_sgemm_fp16_128x32_nn
                    4.29%  383.70ms     11684  32.840us     768ns  12.133ms  [CUDA memcpy DtoH]
                    3.83%  342.70ms     66310  5.1680us  3.6480us  12.031us  void elemWiseRNNcell<__half, __half, float, cudnnRNNMode_t=2, cudnnRNNBiasMode_t=2>(int, int, int, int, int, bool, __half const *, __half const *, __half const *, __half const *, __half const *, __half const *, __half const *, __half*, __half*, __half*, __half*, __half*, cudnnRNNClipMode_t, cudnnNanPropagation_t, float, float)
                    2.94%  263.32ms     56030  4.6990us  3.4240us  12.384us  void LSTM_elementWise_bp1<__half, __half, float>(int, int, __half*, __half*, __half*, __half*, __half*, __half*, __half*, __half*, __half*, int, int, cudnnRNNClipMode_t, cudnnNanPropagation_t, float, float)
                    1.69%  151.03ms       200  755.17us  295.00us  1.1873ms  maxwell_fp16_sgemm_fp16_32x128_nt
                    1.42%  126.85ms         8  15.856ms  12.120ms  18.044ms  void cudnn::detail::dgrad_alg1_engine<__half, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, bool=1>(int, int, int, __half const *, int, __half const , int, cudnn::detail::dgrad_alg1_engine<__half, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, bool=1>*, kernel_grad_params, __int64, int, float, int)
                    1.10%  98.827ms     28778  3.4340us  2.3360us  86.783us  [CUDA memcpy DtoD]
                    1.07%  95.536ms        52  1.8372ms  73.823us  3.6299ms  void implicit_convolve_sgemm<__half, __half, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=0, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, bool, int, int)
                    0.72%  64.382ms        71  906.79us  27.744us  1.3906ms  maxwell_fp16_sgemm_fp16_64x64_nn
                    0.58%  51.651ms       338  152.81us     831ns  2.7127ms  [CUDA memcpy HtoD]
                    0.55%  49.383ms        20  2.4691ms  482.07us  5.5466ms  void cudnn::cnn::wgrad_alg1_engine<__half, float, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, bool=1>(int, int, int, __half const *, int, float*, __half const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)
                    0.52%  46.084ms        57  808.49us  15.584us  1.3051ms  maxwell_fp16_sgemm_fp16_32x128_nn
                    0.36%  31.808ms      1344  23.666us  2.3670us  83.231us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<float, float, float, at::native::MulFunctor<float>>, at::detail::Array<char*, int=2>>(int, float, float)
                    0.28%  25.098ms       240  104.58us  46.271us  241.09us  void internal::region_transform_ABC_val<int, int=32, int=32, bool=0, internal::TransformParamsABC<float, internal::TiledMatrixStridedBatch<internal::RawData<__half const , int>, internal::Tile_Col<int, int=32>>, internal::TiledMatrixStridedBatch<internal::RawData<__half const , int>, internal::Tile_Col<int, int=32>>, internal::TiledMatrixStridedBatch<internal::RawData<__half, int>, internal::Tile_Col<int, int=32>>>>(float, internal::region_transform_ABC_val<int, int=32, int=32, bool=0, internal::TransformParamsABC<float, internal::TiledMatrixStridedBatch<internal::RawData<__half const , int>::Math, internal::Tile_Col<int, int=32>>, internal::TiledMatrixStridedBatch<internal::RawData<__half const , int>, internal::Tile_Col<int, int=32>>, internal::TiledMatrixStridedBatch<internal::RawData<__half, int>, internal::Tile_Col<int, int=32>>>>, float)
                    0.27%  24.588ms       720  34.150us  2.4640us  119.33us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BinaryFunctor<float, float, float, at::native::AddFunctor<float>>, at::detail::Array<char*, int=3>>(int, float, float)
                    0.27%  24.153ms        10  2.4153ms  2.0680ms  2.6152ms  void precomputed_convolve_sgemm<__half, int=1024, int=5, int=5, int=4, int=3, int=3, int=1, bool=0>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, int*)
                    0.23%  20.723ms       708  29.269us  3.1360us  99.519us  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE1_clEvENKUlvE18_clEvEUlN3c104HalfEE_NS_6detail5ArrayIPcLi2EEE23TrivialOffsetCalculatorILi1EjESE_NS0_6memory12LoadWithCastILi1EEENSF_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_
                    0.20%  17.667ms       510  34.640us  2.7520us  95.775us  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE1_clEvENKUlvE6_clEvEUlfE_NS_6detail5ArrayIPcLi2EEE23TrivialOffsetCalculatorILi1EjESC_NS0_6memory12LoadWithCastILi1EEENSD_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_
                    0.19%  16.677ms        50  333.53us  98.175us  1.0340ms  _ZN2at6native81_GLOBAL__N__57_tmpxft_000107ea_00000000_14_AmpKernels_compute_86_cpp1_ii_3810c27325multi_tensor_apply_kernelINS1_18TensorListMetadataILi1EEENS1_14UnaryOpFunctorIfLi1ELi1ELi0EEEJZZZNS0_47_amp_foreach_non_finite_check_and_unscale_cuda_EN3c108ArrayRefINS_6TensorEEERS9_RKS9_ENKUlvE_clEvENKUlvE2_clEvEUlfE_EEEvT_T0_DpT1_
                    0.18%  15.963ms       539  29.615us  3.2000us  99.487us  void at::native::unrolled_elementwise_kernel<at::native::BinaryFunctor<float, float, float, at::native::MulFunctor<float>>, at::detail::Array<char*, int=3>, OffsetCalculator<int=2, unsigned int, bool=0>, OffsetCalculator<int=1, unsigned int, bool=0>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, float, float, float, float, at::native::MulFunctor<float>, at::native::BinaryFunctor<float, float, float, at::native::MulFunctor<float>>)
                    0.16%  14.581ms        12  1.2150ms  477.18us  1.6085ms  void precomputed_convolve_sgemm<__half, int=512, int=6, int=8, int=3, int=3, int=5, int=1, bool=0>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, int*)
                    0.16%  14.427ms       354  40.753us  2.2390us  141.82us  void at::native::vectorized_elementwise_kernel<int=4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, int=1>>(int, c10::Half, at::native::FillFunctor<c10::Half>)
                    0.14%  12.650ms       100  126.50us  87.679us  206.49us  void gemmk1_kernel<float, int=256, int=5, bool=0, bool=0, bool=1, bool=0, cublasGemvTensorStridedBatched<__half const >, cublasGemvTensorStridedBatched<__half const >, cublasGemvTensorStridedBatched<__half>, float, bool=1, bool=1>(cublasGemmk1Params<float, __half const , cublasGemvTensorStridedBatched<__half const >, cublasGemvTensorStridedBatched<__half const >, __half, biasType<cublasGemvTensorStridedBatched<__half const >::value_type, __half>::type>)
                    0.12%  10.924ms       600  18.207us  4.0000us  51.200us  void at::native::reduce_kernel<int=512, int=1, at::native::ReduceOp<float, at::native::NormTwoOps<float, float>, unsigned int, float, int=4>>(float)
                    0.12%  10.662ms        38  280.58us  52.511us  1.4600ms  void implicit_convolve_sgemm<__half, __half, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=0, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, bool, int, int)
                    0.12%  10.500ms       863  12.167us  2.1750us  633.05us  void at::native::vectorized_elementwise_kernel<int=4, at::native::FillFunctor<float>, at::detail::Array<char*, int=1>>(int, float, at::native::FillFunctor<float>)
                    0.10%  8.6114ms        10  861.14us  224.32us  1.4007ms  void at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_log_beta_gpu_kernel<float, long>(float*, at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_log_beta_gpu_kernel<float, long> const *, long const *, long, long const *, long const , long, long, long, long, long, long, long, long const , long, long, long)
                    0.10%  8.5704ms         2  4.2852ms  3.3402ms  5.2302ms  void cudnn::detail::dgrad_engine<__half, int=128, int=6, int=8, int=3, int=3, int=5, bool=0>(int, int, int, __half const *, int, __half const , int, cudnn::detail::dgrad_engine<__half, int=128, int=6, int=8, int=3, int=3, int=5, bool=0>*, kernel_grad_params, __int64, int, __int64, int, float, int, int, int)
                    0.09%  8.0129ms       177  45.270us  2.7510us  158.27us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_19addcdiv_cuda_kernelERNS_18TensorIteratorBaseERKN3c106ScalarEENKUlvE_clEvENKUlvE6_clEvEUlfffE_NS_6detail5ArrayIPcLi4EEEEEviT0_T1_
                    0.07%  6.0672ms       177  34.277us  2.4640us  119.42us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_19addcmul_cuda_kernelERNS_18TensorIteratorBaseERKN3c106ScalarEENKUlvE_clEvENKUlvE6_clEvEUlfffE_NS_6detail5ArrayIPcLi4EEEEEviT0_T1_
                    0.06%  5.5280ms        10  552.80us  187.39us  879.03us  void at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_log_alpha_gpu_kernel<float, long>(float*, at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_log_alpha_gpu_kernel<float, long> const *, long const *, long, long const *, long const , long, float, long, long, long, long, long, long, long const , long, long, long)
                    0.06%  4.9548ms       100  49.548us  13.951us  73.694us  void GENERIC_elementWise_bp2<__half, __half, float, int=4, cudnnRNNBiasMode_t=2>(int, int, __half*, __half*, cudnn::reduced_divisor, __half*)
                    0.05%  4.3795ms       187  23.419us  2.6560us  82.719us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_16sqrt_kernel_cudaERNS_18TensorIteratorBaseEENKUlvE_clEvENKUlvE2_clEvEUlfE_NS_6detail5ArrayIPcLi2EEEEEviT0_T1_
                    0.05%  4.3233ms       187  23.119us  2.4310us  82.751us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<float, float, float, at::native::AddFunctor<float>>, at::detail::Array<char*, int=2>>(int, float, float)
                    0.03%  2.6501ms        50  53.001us  22.175us  69.631us  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE1_clEvENKUlvE18_clEvEUlN3c104HalfEE_NS_6detail5ArrayIPcLi2EEE16OffsetCalculatorILi1EjLb0EESE_NS0_6memory12LoadWithCastILi1EEENSF_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_
                    0.02%  1.6882ms         8  211.02us  145.41us  360.35us  void at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_collect_nonblank_gpu_kernel<float, long>(float*, at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_collect_nonblank_gpu_kernel<float, long> const *, long, at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_collect_nonblank_gpu_kernel<float, long> const , at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_collect_nonblank_gpu_kernel<float, long> const , at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_collect_nonblank_gpu_kernel<float, long> const , long const *, long, long const *, long const , long, at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_collect_nonblank_gpu_kernel<float, long> const , long, long, long, long, long, long, long, long, long, long, long, long, long const , long, long, long, long, bool)
                    0.02%  1.4624ms        60  24.374us  11.328us  37.055us  _ZN2at6native13reduce_kernelILi128ELi4ENS0_8ReduceOpIN3c104HalfENS0_14func_wrapper_tIfZNS0_11sum_functorIS4_ffEclERNS_14TensorIteratorEEUlffE_EEjfLi4EEEEEvT1_
                    0.01%  1.3248ms        16  82.798us  29.600us  127.93us  void cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1>(float, cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1>, cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1>, cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1>, cudnnTensorStruct, __half const *, float, __half const , float, cudnnTensorStruct*, cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1> const *, cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1>*, cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1> const *, cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1> const , cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1> const , cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1>)
                    0.01%  1.3000ms       112  11.606us  4.2870us  19.520us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_79_GLOBAL__N__55_tmpxft_000115da_00000000_14_Indexing_compute_86_cpp1_ii_ccf5656718masked_fill_kernelIbEEvRNS_14TensorIteratorERKN3c106ScalarEENKUlvE_clEvENKUlvE20_clEvEUlNS6_4HalfEbE_NS_6detail5ArrayIPcLi3EEEEEviT0_T1_
                    0.01%  904.02us        50  18.080us  12.032us  23.711us  void at::native::batch_norm_collect_statistics_channels_last_kernel<at::native::Var, float, float, int=4>(float const *, float*, float, float const * volatile *, int*, int, int, float const *)
                    0.01%  879.28us        50  17.585us  9.4080us  23.167us  void at::native::batch_norm_backward_reduce_channels_last_kernel<int=4, float, float, float>(float const *, float const , float const *, float const , float const **, float const *, float*, float, float const * volatile *, int*, int, int)
                    0.01%  819.16us        50  16.383us  6.9120us  21.119us  void at::native::batch_norm_backward_elemt_channels_last_kernel<int=4, float, float, float>(float const *, float const , float const *, float const , float const *, float const , float const , at::native::batch_norm_backward_elemt_channels_last_kernel<int=4, float, float, float>*, float const *, int, int)
                    0.01%  749.11us        24  31.212us  10.240us  52.351us  void at::native::unrolled_elementwise_kernel<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::AddFunctor<float>>, at::detail::Array<char*, int=3>, OffsetCalculator<int=2, unsigned int, bool=0>, OffsetCalculator<int=1, unsigned int, bool=0>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, c10::Half, c10::Half, c10::Half, float, at::native::AddFunctor<float>, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::AddFunctor<float>>)
                    0.01%  607.32us        50  12.146us  6.1120us  16.928us  void RNN_bidirectional_accum_bp1_1<__half, __half, float>(__half*, __half*, __half*, int)
                    0.01%  601.69us        60  10.028us  5.7280us  13.760us  void at::native::batch_norm_transform_input_channels_last_kernel<float, float, float, int=4>(float const *, float const , float const *, float const , float const *, float const , at::native::batch_norm_transform_input_channels_last_kernel<float, float, float, int=4>*, int, int, bool)
                    0.01%  597.75us        20  29.887us  13.440us  39.775us  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_79_GLOBAL__N__55_tmpxft_000115da_00000000_14_Indexing_compute_86_cpp1_ii_ccf5656718masked_fill_kernelIbEEvRNS_14TensorIteratorERKN3c106ScalarEENKUlvE_clEvENKUlvE20_clEvEUlNS6_4HalfEbE_NS_6detail5ArrayIPcLi3EEE16OffsetCalculatorILi2EjLb0EESI_ILi1EjLb0EENS0_6memory15LoadWithoutCastENSL_16StoreWithoutCastEEEviT_T0_T1_T2_T3_T4_
                    0.01%  576.82us        22  26.219us  12.895us  33.343us  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE1_clEvENKUlvE18_clEvEUlN3c104HalfEE_NS_6detail5ArrayIPcLi2EEE16OffsetCalculatorILi1EjLb0EESE_NS0_6memory15LoadWithoutCastENSF_16StoreWithoutCastEEEviT_T0_T1_T2_T3_T4_
                    0.01%  476.44us        20  23.822us  22.784us  24.864us  void cudnn::ops::convertTensor_kernel<float, __half, float, cudnnKernelDataType_t=0>(float, float const *, cudnn::ops::convertTensor_kernel<float, __half, float, cudnnKernelDataType_t=0>, __half*, unsigned long)
                    0.01%  459.77us        12  38.314us  34.144us  43.039us  hgemm_32x32x32_NT_vec
                    0.00%  415.35us        12  34.612us  16.384us  50.239us  void cudnn::bn_fw_tr_1C11_kernel_NCHW<__half, float, int=512, bool=1, int=1>(cudnnTensorStruct, __half const *, cudnn::bn_fw_tr_1C11_kernel_NCHW<__half, float, int=512, bool=1, int=1>, cudnnTensorStruct*, float const *, float const , cudnnTensorStruct*, cudnnTensorStruct*, cudnnTensorStruct**, float const *, float const *, float const *, cudnnTensorStruct*, cudnnTensorStruct*)
                    0.00%  376.67us        10  37.666us  37.504us  38.016us  void at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrayBatchedCopy<float, unsigned int, int=1, int=128, int=1>(float*, at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrInputTensorMetadata<at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrayBatchedCopy<float, unsigned int, int=1, int=128, int=1>, unsigned int, int=128, int=1>, at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::TensorSizeStride<at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrInputTensorMetadata, unsigned int=4>, int, at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrInputTensorMetadata)
                    0.00%  369.44us         2  184.72us  136.93us  232.51us  void at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_collect_gpu_kernel<float, long>(float*, at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_collect_gpu_kernel<float, long> const *, long, at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_collect_gpu_kernel<float, long> const , at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_collect_gpu_kernel<float, long> const , at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_collect_gpu_kernel<float, long> const , long const *, long, long const *, long const , long, at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_collect_gpu_kernel<float, long> const , long, long, long, long, long, long, long, long, long, long, long, long, long const , long, long, long, long, bool)
                    0.00%  368.06us        10  36.805us  15.744us  50.783us  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_24hardtanh_backward_kernelERNS_14TensorIteratorERKN3c106ScalarES7_ENKUlvE_clEvENKUlvE4_clEvEUlNS4_4HalfESA_E_NS_6detail5ArrayIPcLi3EEE16OffsetCalculatorILi2EjLb0EESG_ILi1EjLb0EENS0_6memory15LoadWithoutCastENSJ_16StoreWithoutCastEEEviT_T0_T1_T2_T3_T4_
                    0.00%  279.97us       303     923ns     831ns  2.1120us  [CUDA memset]
                    0.00%  278.97us        90  3.0990us  2.3680us  4.0960us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<long, long, long, at::native::AddFunctor<long>>, at::detail::Array<char*, int=2>>(int, long, long)
                    0.00%  277.72us         8  34.715us  28.224us  39.456us  hgemm_32x32x32_TN
                    0.00%  265.85us        20  13.292us  7.9360us  20.703us  _ZN2at6native13reduce_kernelILi512ELi1ENS0_8ReduceOpIN3c104HalfENS0_14func_wrapper_tIS4_ZNS0_11sum_functorIS4_fS4_EclERNS_14TensorIteratorEEUlffE_EEjS4_Li4EEEEEvT1_
                    0.00%  253.08us        24  10.545us  4.4800us  17.408us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_84_GLOBAL__N__60_tmpxft_00012309_00000000_14_TensorCompare_compute_86_cpp1_ii_d0af11f724clamp_scalar_kernel_implERNS_18TensorIteratorBaseERKN3c106ScalarES8_ENKUlvE_clEvENKUlvE14_clEvEUlNS5_4HalfEE_NS_6detail5ArrayIPcLi2EEEEEviT0_T1_
                    0.00%  239.87us        40  5.9960us  4.0320us  13.215us  void at::native::unrolled_elementwise_kernel<at::native::BinaryFunctor<float, float, float, at::native::AddFunctor<float>>, at::detail::Array<char*, int=3>, OffsetCalculator<int=2, unsigned int, bool=0>, OffsetCalculator<int=1, unsigned int, bool=0>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, float, float, float, float, at::native::AddFunctor<float>, at::native::BinaryFunctor<float, float, float, at::native::AddFunctor<float>>)
                    0.00%  218.14us        10  21.814us  9.5030us  28.095us  void cudnn::ops::scalePackedTensor_kernel<__half, float>(long, __half*, float)
                    0.00%  196.54us        28  7.0190us  4.1600us  9.6630us  _ZN2at6native13reduce_kernelILi512ELi1ENS0_8ReduceOpIfNS0_14func_wrapper_tIfZNS0_11sum_functorIfffEclERNS_14TensorIteratorEEUlffE_EEjfLi4EEEEEvT1_
                    0.00%  181.41us        10  18.140us  7.4560us  24.768us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_24hardtanh_backward_kernelERNS_14TensorIteratorERKN3c106ScalarES7_ENKUlvE_clEvENKUlvE4_clEvEUlNS4_4HalfESA_E_NS_6detail5ArrayIPcLi3EEEEEviT0_T1_
                    0.00%  179.77us        50  3.5950us  3.1360us  5.0560us  _ZN2at6native84_GLOBAL__N__60_tmpxft_000119e1_00000000_14_Normalization_compute_86_cpp1_ii_5c38458745unrolled_elementwise_kernel_for_multi_outputsILi3EZZZNS1_34batch_norm_update_stats_and_invertERKNS_6TensorES5_S5_S5_ddlENKUlvE_clEvENKUlvE2_clEvEUlffffE_NS_6detail5ArrayIPcLi7EEE23TrivialOffsetCalculatorILi4EjESD_ILi3EjEEEviT0_T1_T2_T3_
                    0.00%  126.34us         4  31.584us  27.776us  34.112us  void cudnn::bn_fw_tr_1C11_singleread_specialized<__half2, int=512, int=1, int=2, int=20>(cudnnTensorStruct, __half2 const *, cudnn::bn_fw_tr_1C11_singleread_specialized<__half2, int=512, int=1, int=2, int=20>, cudnnTensorStruct*, float const *, float const , float, float, float*, float const *, float const *, float const *, float, float, cudnn::reduced_divisor, int, float*, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)
                    0.00%  125.66us         4  31.415us  15.168us  48.799us  void cudnn::bn_fw_inf_1C11_kernel_NCHW<__half, float, bool=1, int=1>(float, cudnn::bn_fw_inf_1C11_kernel_NCHW<__half, float, bool=1, int=1>, cudnnTensorStruct, __half const *, float, cudnnTensorStruct*, float, cudnn::bn_fw_inf_1C11_kernel_NCHW<__half, float, bool=1, int=1> const *, cudnn::bn_fw_inf_1C11_kernel_NCHW<__half, float, bool=1, int=1> const , cudnn::bn_fw_inf_1C11_kernel_NCHW<__half, float, bool=1, int=1> const , cudnn::bn_fw_inf_1C11_kernel_NCHW<__half, float, bool=1, int=1> const , cudnn::bn_fw_inf_1C11_kernel_NCHW<__half, float, bool=1, int=1>)
                    0.00%  89.118us        24  3.7130us  2.6560us  4.9600us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_15exp_kernel_cudaERNS_18TensorIteratorBaseEENKUlvE_clEvENKUlvE2_clEvEUlfE_NS_6detail5ArrayIPcLi2EEEEEviT0_T1_
                    0.00%  82.942us        22  3.7700us  3.2320us  4.6390us  void cudnn::cnn::kern_precompute_indices<bool=0>(int*, int, int, int, int, int, int)
                    0.00%  82.911us        26  3.1880us  2.4640us  4.0310us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<float, float, bool, at::native::CompareEqFunctor<float>>, at::detail::Array<char*, int=2>>(int, float, float)
                    0.00%  72.383us         8  9.0470us  8.2880us  10.208us  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_84_GLOBAL__N__60_tmpxft_00012309_00000000_14_TensorCompare_compute_86_cpp1_ii_d0af11f717where_kernel_implERNS_14TensorIteratorEN3c1010ScalarTypeEENKUlvE_clEvENKUlvE6_clEvEUlbffE_NS_6detail5ArrayIPcLi4EEE16OffsetCalculatorILi3EjLb0EESE_ILi1EjLb0EENS0_6memory15LoadWithoutCastENSH_16StoreWithoutCastEEEviT_T0_T1_T2_T3_T4_
                    0.00%  71.582us        10  7.1580us  6.1120us  12.096us  void at::native::reduce_kernel<int=512, int=1, at::native::ReduceOp<float, at::native::MaxOps<float>, unsigned int, float, int=4>>(float)
                    0.00%  64.155us        20  3.2070us  2.4320us  4.0000us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_84_GLOBAL__N__60_tmpxft_00012309_00000000_14_TensorCompare_compute_86_cpp1_ii_d0af11f717where_kernel_implERNS_14TensorIteratorEN3c1010ScalarTypeEENKUlvE_clEvENKUlvE6_clEvEUlbffE_NS_6detail5ArrayIPcLi4EEEEEviT0_T1_
                    0.00%  63.583us         8  7.9470us  7.5840us  9.1200us  void at::native::reduce_kernel<int=512, int=1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::MaxNanFunctor<float>>, unsigned int, float, int=4>>(float)
                    0.00%  58.879us        20  2.9430us  2.5600us  3.4560us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BinaryFunctor<float, float, float, at::native::MulFunctor<float>>, at::detail::Array<char*, int=3>>(int, float, float)
                    0.00%  58.528us        12  4.8770us  4.0640us  6.4320us  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE1_clEvENKUlvE8_clEvEUliE_NS_6detail5ArrayIPcLi2EEE23TrivialOffsetCalculatorILi1EjESC_NS0_6memory12LoadWithCastILi1EEENSD_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_
                    0.00%  55.999us         2  27.999us  27.071us  28.928us  void cudnn::bn_bw_1C11_singleread_specialized<__half2, int=512, int=1, int=2, int=14>(float, float, float, float, cudnnTensorStruct, __half2 const *, cudnn::bn_bw_1C11_singleread_specialized<__half2, int=512, int=1, int=2, int=14>, __half2 const , cudnn::bn_bw_1C11_singleread_specialized<__half2, int=512, int=1, int=2, int=14>, cudnnTensorStruct*, float const *, float*, float const *, float const , float const , float, cudnn::reduced_divisor, int, float*, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)
                    0.00%  55.007us        12  4.5830us  2.6880us  5.1210us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BinaryFunctor<float, float, float, at::native::DivFunctor<float>>, at::detail::Array<char*, int=3>>(int, float, float)
                    0.00%  50.590us        10  5.0590us  4.8330us  5.1530us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_22reciprocal_kernel_cudaERNS_18TensorIteratorBaseEENKUlvE_clEvENKUlvE0_clEvEUldE_NS_6detail5ArrayIPcLi2EEEEEviT0_T1_
                    0.00%  49.601us        10  4.9600us  4.5760us  5.3440us  void _GLOBAL__N__54_tmpxft_000120b7_00000000_14_SoftMax_compute_86_cpp1_ii_9f978f63::softmax_warp_forward<c10::Half, float, float, int=5, bool=1>(float*, c10::Half const *, int, int, int)
                    0.00%  48.959us        10  4.8950us  4.5760us  5.1840us  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE1_clEvENKUlvE4_clEvEUldE_NS_6detail5ArrayIPcLi2EEE23TrivialOffsetCalculatorILi1EjESC_NS0_6memory12LoadWithCastILi1EEENSD_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_
                    0.00%  46.368us         8  5.7960us  5.3760us  6.3040us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_15log_kernel_cudaERNS_18TensorIteratorBaseEENKUlvE_clEvENKUlvE2_clEvEUlfE_NS_6detail5ArrayIPcLi2EEEEEviT0_T1_
                    0.00%  42.398us         8  5.2990us  3.6480us  9.6000us  _ZN2at6native13reduce_kernelILi512ELi1ENS0_8ReduceOpIlNS0_14func_wrapper_tIlZNS0_11sum_functorIlllEclERNS_14TensorIteratorEEUlllE_EEjlLi4EEEEEvT1_
                    0.00%  41.085us        16  2.5670us  2.4000us  3.4560us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<int, int, int, at::native::AddFunctor<int>>, at::detail::Array<char*, int=2>>(int, int, int)
                    0.00%  40.670us        10  4.0670us  3.9040us  4.2880us  void _GLOBAL__N__54_tmpxft_000120b7_00000000_14_SoftMax_compute_86_cpp1_ii_9f978f63::softmax_warp_backward<float, c10::Half, float, int=5, bool=1>(c10::Half*, float const *, float const , int, int, int)
                    0.00%  36.480us        10  3.6480us  3.1680us  4.2880us  at::native::amp_update_scale_cuda_kernel(float*, int*, float*, double, double, int)
                    0.00%  35.040us         2  17.520us  16.640us  18.400us  maxwell_sgemm_fp16_128x32_nt
                    0.00%  34.497us        10  3.4490us  3.2960us  3.8730us  _ZN2at6native29vectorized_elementwise_kernelILi4EZNS0_86_GLOBAL__N__56_tmpxft_00011ac0_00000000_14_PowKernel_compute_86_cpp1_ii_0aea0a57_7240729pow_tensor_scalar_kernel_implIffEEvRNS_18TensorIteratorBaseET0_EUlfE_NS_6detail5ArrayIPcLi2EEEEEviS6_T1_
                    0.00%  32.189us        10  3.2180us  2.9440us  4.0000us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_84_GLOBAL__N__60_tmpxft_000119e1_00000000_14_Normalization_compute_86_cpp1_ii_5c38458722batch_norm_calc_invstdERKNS_6TensorES5_dENKUlvE_clEvENKUlvE2_clEvEUlfE_NS_6detail5ArrayIPcLi2EEEEEviT0_T1_
                    0.00%  31.648us        10  3.1640us  3.0720us  3.2960us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<float, float, bool, at::native::CompareLTFunctor<float>>, at::detail::Array<char*, int=2>>(int, float, float)
                    0.00%  29.567us        10  2.9560us  2.7520us  3.2320us  void at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_zero_padded_gradients<float>(float*, long const *, long, long, long, long, long, long)
                    0.00%  29.439us         1  29.439us  29.439us  29.439us  void cudnn::bn_fw_tr_1C11_singleread<__half, int=512, bool=1, int=1, int=2, int=20>(cudnnTensorStruct, __half const *, cudnn::bn_fw_tr_1C11_singleread<__half, int=512, bool=1, int=1, int=2, int=20>, cudnnTensorStruct*, float const *, float const , float, float, float*, float const *, float const *, float const *, float, float, cudnn::reduced_divisor, int, float*, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)
                    0.00%  29.407us         8  3.6750us  3.2960us  3.9360us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_79_GLOBAL__N__55_tmpxft_000115da_00000000_14_Indexing_compute_86_cpp1_ii_ccf5656718masked_fill_kernelIbEEvRNS_14TensorIteratorERKN3c106ScalarEENKUlvE_clEvENKUlvE6_clEvEUlfbE_NS_6detail5ArrayIPcLi3EEEEEviT0_T1_
                    0.00%  28.831us         8  3.6030us  2.9760us  5.6000us  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_22reciprocal_kernel_cudaERNS_18TensorIteratorBaseEENKUlvE_clEvENKUlvE2_clEvEUlfE_NS_6detail5ArrayIPcLi2EEE23TrivialOffsetCalculatorILi1EjESC_NS0_6memory12LoadWithCastILi1EEENSD_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_
                    0.00%  28.703us         4  7.1750us  4.2880us  10.240us  void at::native::reduce_kernel<int=512, int=1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, int=4>>(float)
                    0.00%  25.760us         8  3.2200us  2.8800us  3.3600us  void at::native::vectorized_elementwise_kernel<int=4, at::native::AbsFunctor<float>, at::detail::Array<char*, int=2>>(int, float, at::native::AbsFunctor<float>)
                    0.00%  24.256us         1  24.256us  24.256us  24.256us  void cudnn::bn_fw_tr_1C11_singleread_specialized<__half2, int=512, int=1, int=2, int=10>(cudnnTensorStruct, __half2 const *, cudnn::bn_fw_tr_1C11_singleread_specialized<__half2, int=512, int=1, int=2, int=10>, cudnnTensorStruct*, float const *, float const , float, float, float*, float const *, float const *, float const *, float, float, cudnn::reduced_divisor, int, float*, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)
                    0.00%  22.624us         9  2.5130us  2.2400us  3.8400us  void at::native::vectorized_elementwise_kernel<int=4, at::native::FillFunctor<long>, at::detail::Array<char*, int=1>>(int, long, at::native::FillFunctor<long>)
                    0.00%  22.271us         1  22.271us  22.271us  22.271us  void cudnn::bn_bw_1C11_singleread<__half, int=512, bool=1, int=1, int=2, int=14>(float, float, float, float, cudnnTensorStruct, __half const *, cudnn::bn_bw_1C11_singleread<__half, int=512, bool=1, int=1, int=2, int=14>, __half const , cudnn::bn_bw_1C11_singleread<__half, int=512, bool=1, int=1, int=2, int=14>, cudnnTensorStruct*, float const *, float*, float const *, float const , float const , float, cudnn::reduced_divisor, int, float*, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)
                    0.00%  20.063us         1  20.063us  20.063us  20.063us  void cudnn::bn_fw_tr_1C11_singleread<__half, int=512, bool=1, int=1, int=2, int=10>(cudnnTensorStruct, __half const *, cudnn::bn_fw_tr_1C11_singleread<__half, int=512, bool=1, int=1, int=2, int=10>, cudnnTensorStruct*, float const *, float const , float, float, float*, float const *, float const *, float const *, float, float, cudnn::reduced_divisor, int, float*, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)
                    0.00%  16.512us         1  16.512us  16.512us  16.512us  void cudnn::bn_bw_1C11_singleread_specialized<__half2, int=512, int=1, int=2, int=7>(float, float, float, float, cudnnTensorStruct, __half2 const *, cudnn::bn_bw_1C11_singleread_specialized<__half2, int=512, int=1, int=2, int=7>, __half2 const , cudnn::bn_bw_1C11_singleread_specialized<__half2, int=512, int=1, int=2, int=7>, cudnnTensorStruct*, float const *, float*, float const *, float const , float const , float, cudnn::reduced_divisor, int, float*, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)
                    0.00%  13.953us         1  13.953us  13.953us  13.953us  void cudnn::bn_fw_tr_1C11_singleread_specialized<__half2, int=512, int=1, int=2, int=0>(cudnnTensorStruct, __half2 const *, cudnn::bn_fw_tr_1C11_singleread_specialized<__half2, int=512, int=1, int=2, int=0>, cudnnTensorStruct*, float const *, float const , float, float, float*, float const *, float const *, float const *, float, float, cudnn::reduced_divisor, int, float*, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)
                    0.00%  10.976us         3  3.6580us  2.4320us  4.9600us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<long, long, bool, at::native::CompareEqFunctor<long>>, at::detail::Array<char*, int=2>>(int, long, long)
                    0.00%  10.080us         2  5.0400us  4.7680us  5.3120us  void _GLOBAL__N__54_tmpxft_000120b7_00000000_14_SoftMax_compute_86_cpp1_ii_9f978f63::softmax_warp_forward<c10::Half, float, float, int=5, bool=0>(float*, c10::Half const *, int, int, int)
                    0.00%  9.5370us         3  3.1790us  2.4330us  3.7760us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<long, long, bool, at::native::CompareGTFunctor<long>>, at::detail::Array<char*, int=2>>(int, long, long)
                    0.00%  8.7370us         2  4.3680us  4.3200us  4.4170us  void splitKreduce_kernel<float, __half, float, __half, bool=1, bool=0>(cublasSplitKParams<float>, float const *, __half const *, __half*, float const *, float const *, __half const *, void*, long, float*, int*)
                    0.00%  7.0400us         2  3.5200us  2.6880us  4.3520us  void at::native::unrolled_elementwise_kernel<at::native::BUnaryFunctor<float, float, float, at::native::MulFunctor<float>>, at::detail::Array<char*, int=2>, TrivialOffsetCalculator<int=1, unsigned int>, TrivialOffsetCalculator<int=1, unsigned int>, at::native::memory::LoadWithCast<int=1>, at::native::memory::StoreWithCast>(int, float, float, float, float, at::native::MulFunctor<float>, at::native::BUnaryFunctor<float, float, float, at::native::MulFunctor<float>>)
                    0.00%  2.9120us         1  2.9120us  2.9120us  2.9120us  void at::native::vectorized_elementwise_kernel<int=4, at::native::FillFunctor<int>, at::detail::Array<char*, int=1>>(int, int, at::native::FillFunctor<int>)
      API calls:   48.76%  2.80295s    255107  10.987us  4.2960us  12.093ms  cudaLaunchKernel
                   22.30%  1.28205s     40766  31.448us  4.3460us  34.062ms  cudaMemcpyAsync
                   10.87%  624.79ms     12000  52.065us  1.1920us  69.258ms  cudaStreamSynchronize
                    7.14%  410.40ms        40  10.260ms  2.1900us  195.60ms  cudaFree
                    1.87%  107.27ms    135344     792ns     452ns  2.8425ms  cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
                    1.80%  103.38ms    117695     878ns     531ns  4.1780ms  cudaEventRecord
                    1.76%  100.97ms    115241     876ns     540ns  1.0535ms  cudaEventCreateWithFlags
                    1.67%  96.277ms    219327     438ns     281ns  675.13us  cudaGetDevice
                    1.12%  64.358ms    115142     558ns     440ns  1.4158ms  cudaEventDestroy
                    1.07%  61.220ms    229505     266ns     133ns  733.72us  cudaGetLastError
                    0.36%  20.417ms        35  583.35us  5.5620us  1.6734ms  cudaHostAlloc
                    0.34%  19.523ms        25  780.93us  5.8530us  6.6372ms  cudaDeviceSynchronize
                    0.29%  16.878ms       151  111.78us  3.0460us  1.6492ms  cudaMalloc
                    0.19%  11.017ms      2251  4.8940us  2.0110us  26.726us  cudaFuncGetAttributes
                    0.12%  7.1829ms      5147  1.3950us     654ns  22.389us  cudaStreamWaitEvent
                    0.06%  3.2796ms       568  5.7740us  2.2780us  31.002us  cudaStreamDestroy
                    0.05%  3.1446ms      1206  2.6070us     922ns  19.860us  cudaEventQuery
                    0.05%  2.5877ms       303  8.5400us  2.6900us  41.106us  cudaMemsetAsync
                    0.04%  2.3395ms      4246     550ns     327ns  9.7500us  cudaSetDevice
                    0.03%  1.7817ms       272  6.5500us  1.7570us  292.50us  cudaStreamCreateWithPriority
                    0.03%  1.4872ms       300  4.9570us  1.7600us  40.186us  cudaStreamCreate
                    0.02%  1.4128ms      1023  1.3810us     450ns  12.458us  cudaStreamIsCapturing
                    0.01%  838.73us       949     883ns     605ns  4.7600us  cudaStreamGetCaptureInfo
                    0.01%  789.24us        84  9.3950us  2.2390us  137.37us  cudaStreamCreateWithFlags
                    0.01%  506.07us       392  1.2910us     125ns  64.078us  cuDeviceGetAttribute
                    0.01%  402.77us         2  201.38us  147.60us  255.17us  cudaGetDeviceProperties
                    0.01%  342.17us       240  1.4250us     570ns  11.548us  cudaPointerGetAttributes
                    0.00%  253.21us        34  7.4470us  6.2560us  23.052us  cudaMemcpy
                    0.00%  168.87us       730     231ns     131ns  1.0280us  cuGetProcAddress
                    0.00%  76.355us         4  19.088us  11.828us  30.140us  cuDeviceGetName
                    0.00%  42.788us        54     792ns     295ns  3.2870us  cudaDeviceGetAttribute
                    0.00%  18.773us        28     670ns     162ns  5.3890us  cuDevicePrimaryCtxGetState
                    0.00%  13.384us         1  13.384us  13.384us  13.384us  cudaDeviceGetPCIBusId
                    0.00%  11.697us         8  1.4620us     555ns  3.4170us  cudaStreamGetCaptureInfo
                    0.00%  9.9930us         2  4.9960us  4.1170us  5.8760us  cudaEventSynchronize
                    0.00%  5.1870us         2  2.5930us  2.4300us  2.7570us  cudaDeviceGetStreamPriorityRange
                    0.00%  4.8610us         2  2.4300us  2.3000us  2.5610us  cuInit
                    0.00%  4.6860us         2  2.3430us  1.3690us  3.3170us  cudaHostGetDevicePointer
                    0.00%  2.1440us         3     714ns     240ns  1.6520us  cuDeviceGetCount
                    0.00%  1.8890us         3     629ns     403ns     886ns  cudaDriverGetVersion
                    0.00%  1.4460us         4     361ns     259ns     455ns  cuDeviceTotalMem
                    0.00%  1.1360us         4     284ns     234ns     349ns  cuDeviceGet
                    0.00%  1.1270us         2     563ns     434ns     693ns  cudaGetDeviceCount
                    0.00%  1.0730us         1  1.0730us  1.0730us  1.0730us  cudaGetSymbolAddress
                    0.00%     793ns         4     198ns     173ns     208ns  cuDeviceGetUuid
                    0.00%     413ns         2     206ns     183ns     230ns  cuDriverGetVersion

==47590== NVTX result:
==47590==   Thread "<unnamed>" (id = 3196045056)
==47590==     Domain "NCCL"
==47590==       Range "ncclGroupEnd"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  3.8441ms       590  6.5150us  5.6360us  20.000us  ncclGroupEnd
No kernels were profiled in this range.
No API activities were profiled in this range.

==47590==       Range "ncclGroupStart"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  992.50us       590  1.6820us  1.3900us  35.823us  ncclGroupStart
No kernels were profiled in this range.
No API activities were profiled in this range.

==47590==       Range "ncclReduce"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  386.44us       590     654ns     499ns  3.2860us  ncclReduce
No kernels were profiled in this range.
No API activities were profiled in this range.

==47590==   Thread "<unnamed>" (id = 4096450752)
==47590==     Domain "NCCL"
==47590==       Range "ncclAllGather"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  6.2070us         9     689ns     612ns     828ns  ncclAllGather
No kernels were profiled in this range.
No API activities were profiled in this range.

==47590==       Range "ncclAllReduce"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  51.010us        49  1.0410us     522ns  6.8290us  ncclAllReduce
No kernels were profiled in this range.
No API activities were profiled in this range.

==47590==       Range "ncclBroadcast"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  186.97us       301     621ns     454ns  7.6660us  ncclBroadcast
No kernels were profiled in this range.
No API activities were profiled in this range.

==47590==       Range "ncclCommInitRank"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  5.4440us         1  5.4440us  5.4440us  5.4440us  ncclCommInitRank
No kernels were profiled in this range.
No API activities were profiled in this range.

==47590==       Range "ncclGroupEnd"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  31.389ms       360  87.191us  4.8220us  28.917ms  ncclGroupEnd
 GPU activities:  100.00%  23.361us         9  2.5950us  2.3680us  3.4560us  [CUDA memcpy DtoD]
      API calls:  100.00%  161.25us         9  17.916us  13.874us  26.960us  cudaMemcpyAsync

==47590==       Range "ncclGroupStart"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  615.81us       360  1.7100us  1.2140us  29.408us  ncclGroupStart
No kernels were profiled in this range.
No API activities were profiled in this range.

