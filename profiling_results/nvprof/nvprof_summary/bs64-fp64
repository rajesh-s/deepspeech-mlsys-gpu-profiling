==11140== NVPROF is profiling process 11140, command: python train.py +configs=librispeech
==11140== Warning: Profiling results might be incorrect with current version of nvcc compiler used to compile cuda app. Compile with nvcc compiler 9.0 or later version to get correct profiling results. Ignore this warning if code is already compiled with the recommended nvcc version 
==11140== Profiling application: python train.py +configs=librispeech
==11140== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   62.37%  56.8286s    186316  305.01us  101.70us  932.44us  maxwell_fp16_sgemm_fp16_128x32_nn
                   10.17%  9.26926s      6220  1.4902ms  68.480us  61.964ms  maxwell_fp16_sgemm_fp16_32x128_nt
                    5.24%  4.77515s       130  36.732ms  829.33us  55.135ms  maxwell_fp16_sgemm_fp16_32x128_nn
                    2.94%  2.67791s        20  133.90ms  33.345ms  234.42ms  void wgrad_alg0_engine<__half, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, int=512>(int, int, int, __half const *, int, __half*, __half const *, kernel_grad_params, __int64, int, float, int, int, int, int)
                    2.88%  2.62060s     67043  39.088us  2.3360us  1.5527ms  [CUDA memcpy DtoD]
                    2.57%  2.33954s      2920  801.21us  741.14us  865.40us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::AddFunctor<float>>, at::detail::Array<char*, int=3>>(int, c10::Half, c10::Half)
                    2.09%  1.90132s      2174  874.57us  652.18us  1.4612ms  maxwell_fp16_sgemm_fp16_64x64_nn
                    1.74%  1.58642s       338  4.6935ms     831ns  44.871ms  [CUDA memcpy HtoD]
                    1.69%  1.53835s      6194  248.36us  2.5280us  1.0550ms  void at::native::vectorized_elementwise_kernel<int=4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, int=1>>(int, c10::Half, at::native::FillFunctor<c10::Half>)
                    1.67%  1.52293s     96670  15.753us  3.6480us  47.295us  void elemWiseRNNcell<__half, __half, float, cudnnRNNMode_t=2, cudnnRNNBiasMode_t=2>(int, int, int, int, int, bool, __half const *, __half const *, __half const *, __half const *, __half const *, __half const *, __half const *, __half*, __half*, __half*, __half*, __half*, cudnnRNNClipMode_t, cudnnNanPropagation_t, float, float)
                    0.96%  872.43ms    487292  1.7900us     959ns  13.357ms  [CUDA memcpy DtoH]
                    0.93%  847.99ms     74820  11.333us  3.2640us  90.111us  void LSTM_elementWise_bp1<__half, __half, float>(int, int, __half*, __half*, __half*, __half*, __half*, __half*, __half*, __half*, __half*, int, int, cudnnRNNClipMode_t, cudnnNanPropagation_t, float, float)
                    0.60%  546.16ms      2790  195.76us  81.951us  2.2452ms  void gemmk1_kernel<float, int=256, int=5, bool=0, bool=0, bool=1, bool=0, cublasGemvTensorStridedBatched<__half const >, cublasGemvTensorStridedBatched<__half const >, cublasGemvTensorStridedBatched<__half>, float, bool=1, bool=1>(cublasGemmk1Params<float, __half const , cublasGemvTensorStridedBatched<__half const >, cublasGemvTensorStridedBatched<__half const >, __half, biasType<cublasGemvTensorStridedBatched<__half const >::value_type, __half>::type>)
                    0.48%  439.43ms      8416  52.213us  4.1920us  17.031ms  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE1_clEvENKUlvE18_clEvEUlN3c104HalfEE_NS_6detail5ArrayIPcLi2EEE16OffsetCalculatorILi1EjLb0EESE_NS0_6memory15LoadWithoutCastENSF_16StoreWithoutCastEEEviT_T0_T1_T2_T3_T4_
                    0.48%  435.25ms      5558  78.310us  59.616us  93.823us  maxwell_gcgemm_32x32_nt
                    0.26%  236.19ms        12  19.682ms  17.781ms  32.199ms  void precomputed_convolve_sgemm<__half, int=1024, int=5, int=5, int=4, int=3, int=3, int=1, bool=0>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, int*)
                    0.25%  227.92ms       100  2.2792ms  1.2142ms  3.3658ms  void GENERIC_elementWise_bp2<__half, __half, float, int=4, cudnnRNNBiasMode_t=2>(int, int, __half*, __half*, cudnn::reduced_divisor, __half*)
                    0.23%  211.25ms        50  4.2249ms  4.1941ms  4.2944ms  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE1_clEvENKUlvE18_clEvEUlN3c104HalfEE_NS_6detail5ArrayIPcLi2EEE16OffsetCalculatorILi1EjLb0EESE_NS0_6memory12LoadWithCastILi1EEENSF_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_
                    0.23%  208.99ms        20  10.450ms  10.402ms  10.588ms  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_79_GLOBAL__N__55_tmpxft_000115da_00000000_14_Indexing_compute_86_cpp1_ii_ccf5656718masked_fill_kernelIbEEvRNS_14TensorIteratorERKN3c106ScalarEENKUlvE_clEvENKUlvE20_clEvEUlNS6_4HalfEbE_NS_6detail5ArrayIPcLi3EEE16OffsetCalculatorILi2EjLb0EESI_ILi1EjLb0EENS0_6memory15LoadWithoutCastENSL_16StoreWithoutCastEEEviT_T0_T1_T2_T3_T4_
                    0.20%  178.91ms      3129  57.179us  44.735us  68.031us  void fft2d_r2c_32x32<__half, bool=0, unsigned int=0, bool=0>(float2*, __half const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)
                    0.16%  144.10ms      3129  46.051us  38.560us  64.991us  void fft2d_c2r_32x32<__half, bool=1, bool=0, unsigned int=0, bool=0, bool=0>(__half*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, __half*, __half*, int2, int, int)
                    0.14%  131.65ms      2429  54.199us  43.648us  73.663us  void fft2d_c2r_32x32<__half, bool=0, bool=0, unsigned int=0, bool=0, bool=0>(__half*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, __half*, __half*, int2, int, int)
                    0.13%  120.87ms      2429  49.762us  39.968us  58.239us  void fft2d_r2c_32x32<__half, bool=1, unsigned int=0, bool=0>(float2*, __half const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)
                    0.13%  120.23ms        20  6.0114ms  3.9873ms  8.0305ms  void cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1>(float, cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1>, cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1>, cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1>, cudnnTensorStruct, __half const *, float, __half const , float, cudnnTensorStruct*, cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1> const *, cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1>*, cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1> const *, cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1> const , cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1> const , cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1>)
                    0.13%  114.36ms        24  4.7651ms  4.3133ms  7.6810ms  void implicit_convolve_sgemm<__half, __half, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=0, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, bool, int, int)
                    0.12%  107.60ms        10  10.760ms  10.677ms  10.941ms  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_24hardtanh_backward_kernelERNS_14TensorIteratorERKN3c106ScalarES7_ENKUlvE_clEvENKUlvE4_clEvEUlNS4_4HalfESA_E_NS_6detail5ArrayIPcLi3EEE16OffsetCalculatorILi2EjLb0EESG_ILi1EjLb0EENS0_6memory15LoadWithoutCastENSJ_16StoreWithoutCastEEEviT_T0_T1_T2_T3_T4_
                    0.12%  106.46ms       112  950.55us  573.98us  1.8570ms  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_79_GLOBAL__N__55_tmpxft_000115da_00000000_14_Indexing_compute_86_cpp1_ii_ccf5656718masked_fill_kernelIbEEvRNS_14TensorIteratorERKN3c106ScalarEENKUlvE_clEvENKUlvE20_clEvEUlNS6_4HalfEbE_NS_6detail5ArrayIPcLi3EEEEEviT0_T1_
                    0.09%  86.144ms        60  1.4357ms  1.3260ms  2.1736ms  _ZN2at6native13reduce_kernelILi128ELi4ENS0_8ReduceOpIN3c104HalfENS0_14func_wrapper_tIfZNS0_11sum_functorIS4_ffEclERNS_14TensorIteratorEEUlffE_EEjfLi4EEEEEvT1_
                    0.09%  82.264ms      1770  46.476us  26.527us  102.59us  void gemv2N_kernel<int, int, __half, __half, __half, float, int=128, int=4, int=4, int=4, int=1, bool=0, cublasGemvParams<cublasGemvTensorStridedBatched<__half const >, cublasGemvTensorStridedBatched<__half const >, cublasGemvTensorStridedBatched<__half>, float>>(__half const )
                    0.09%  77.945ms        24  3.2477ms  1.9884ms  7.1040ms  void at::native::unrolled_elementwise_kernel<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::AddFunctor<float>>, at::detail::Array<char*, int=3>, OffsetCalculator<int=2, unsigned int, bool=0>, OffsetCalculator<int=1, unsigned int, bool=0>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, c10::Half, c10::Half, c10::Half, float, at::native::AddFunctor<float>, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::AddFunctor<float>>)
                    0.07%  60.016ms       708  84.768us  3.3280us  1.2763ms  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE1_clEvENKUlvE18_clEvEUlN3c104HalfEE_NS_6detail5ArrayIPcLi2EEE23TrivialOffsetCalculatorILi1EjESE_NS0_6memory12LoadWithCastILi1EEENSF_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_
                    0.06%  56.619ms        50  1.1324ms  1.1190ms  1.1488ms  void at::native::batch_norm_backward_elemt_channels_last_kernel<int=4, float, float, float>(float const *, float const , float const *, float const , float const *, float const , float const , at::native::batch_norm_backward_elemt_channels_last_kernel<int=4, float, float, float>*, float const *, int, int)
                    0.06%  50.893ms        20  2.5446ms  1.6124ms  3.3894ms  void cudnn::bn_fw_tr_1C11_kernel_NCHW<__half, float, int=512, bool=1, int=1>(cudnnTensorStruct, __half const *, cudnn::bn_fw_tr_1C11_kernel_NCHW<__half, float, int=512, bool=1, int=1>, cudnnTensorStruct*, float const *, float const , cudnnTensorStruct*, cudnnTensorStruct*, cudnnTensorStruct**, float const *, float const *, float const *, cudnnTensorStruct*, cudnnTensorStruct*)
                    0.06%  50.702ms       510  99.414us  2.7840us  841.56us  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE1_clEvENKUlvE6_clEvEUlfE_NS_6detail5ArrayIPcLi2EEE23TrivialOffsetCalculatorILi1EjESC_NS0_6memory12LoadWithCastILi1EEENSD_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_
                    0.05%  49.873ms        60  831.22us  761.27us  1.2709ms  void at::native::batch_norm_transform_input_channels_last_kernel<float, float, float, int=4>(float const *, float const , float const *, float const , float const *, float const , at::native::batch_norm_transform_input_channels_last_kernel<float, float, float, int=4>*, int, int, bool)
                    0.05%  45.024ms      4536  9.9250us  3.2960us  44.287us  void at::native::unrolled_elementwise_kernel<at::native::FillFunctor<bool>, at::detail::Array<char*, int=1>, OffsetCalculator<int=0, unsigned int, bool=0>, OffsetCalculator<int=1, unsigned int, bool=0>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, bool, at::native::FillFunctor<bool>, char*, int=1, at::detail::Array<char*, int=1>, int=0)
                    0.05%  42.548ms      2348  18.120us  4.1920us  144.16us  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE1_clEvENKUlvE6_clEvEUlfE_NS_6detail5ArrayIPcLi2EEE16OffsetCalculatorILi1EjLb0EESC_NS0_6memory15LoadWithoutCastENSD_16StoreWithoutCastEEEviT_T0_T1_T2_T3_T4_
                    0.04%  35.534ms        50  710.69us  704.22us  717.46us  void at::native::batch_norm_backward_reduce_channels_last_kernel<int=4, float, float, float>(float const *, float const , float const *, float const , float const **, float const *, float*, float, float const * volatile *, int*, int, int)
                    0.04%  33.364ms        50  667.29us  661.27us  672.66us  void at::native::batch_norm_collect_statistics_channels_last_kernel<at::native::Var, float, float, int=4>(float const *, float*, float, float const * volatile *, int*, int, int, float const *)
                    0.03%  27.827ms        50  556.54us  477.72us  733.91us  void RNN_bidirectional_accum_bp1_1<__half, __half, float>(__half*, __half*, __half*, int)
                    0.03%  26.056ms        48  542.83us  344.83us  629.72us  void at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrayBatchedCopy<float, unsigned int, int=2, int=128, int=1>(float*, at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrInputTensorMetadata<at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrayBatchedCopy<float, unsigned int, int=2, int=128, int=1>, unsigned int, int=128, int=1>, at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::TensorSizeStride<at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrInputTensorMetadata, unsigned int=4>, int, at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrInputTensorMetadata)
                    0.03%  24.015ms        50  480.30us  98.878us  1.0972ms  _ZN2at6native81_GLOBAL__N__57_tmpxft_000107ea_00000000_14_AmpKernels_compute_86_cpp1_ii_3810c27325multi_tensor_apply_kernelINS1_18TensorListMetadataILi1EEENS1_14UnaryOpFunctorIfLi1ELi1ELi0EEEJZZZNS0_47_amp_foreach_non_finite_check_and_unscale_cuda_EN3c108ArrayRefINS_6TensorEEERS9_RKS9_ENKUlvE_clEvENKUlvE2_clEvEUlfE_EEEvT_T0_DpT1_
                    0.03%  23.853ms       747  31.931us  2.1440us  632.28us  void at::native::vectorized_elementwise_kernel<int=4, at::native::FillFunctor<float>, at::detail::Array<char*, int=1>>(int, float, at::native::FillFunctor<float>)
                    0.03%  23.036ms       240  95.985us  45.855us  216.67us  void internal::region_transform_ABC_val<int, int=32, int=32, bool=0, internal::TransformParamsABC<float, internal::TiledMatrixStridedBatch<internal::RawData<__half const , int>, internal::Tile_Col<int, int=32>>, internal::TiledMatrixStridedBatch<internal::RawData<__half const , int>, internal::Tile_Col<int, int=32>>, internal::TiledMatrixStridedBatch<internal::RawData<__half, int>, internal::Tile_Col<int, int=32>>>>(float, internal::region_transform_ABC_val<int, int=32, int=32, bool=0, internal::TransformParamsABC<float, internal::TiledMatrixStridedBatch<internal::RawData<__half const , int>::Math, internal::Tile_Col<int, int=32>>, internal::TiledMatrixStridedBatch<internal::RawData<__half const , int>, internal::Tile_Col<int, int=32>>, internal::TiledMatrixStridedBatch<internal::RawData<__half, int>, internal::Tile_Col<int, int=32>>>>, float)
                    0.02%  18.574ms        10  1.8574ms  1.6232ms  2.1750ms  void at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_log_beta_gpu_kernel<float, long>(float*, at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_log_beta_gpu_kernel<float, long> const *, long const *, long, long const *, long const , long, long, long, long, long, long, long, long const , long, long, long)
                    0.02%  18.435ms       545  33.825us  2.5600us  120.86us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BinaryFunctor<float, float, float, at::native::AddFunctor<float>>, at::detail::Array<char*, int=3>>(int, float, float)
                    0.02%  17.897ms        24  745.69us  463.67us  1.5119ms  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_84_GLOBAL__N__60_tmpxft_00012309_00000000_14_TensorCompare_compute_86_cpp1_ii_d0af11f724clamp_scalar_kernel_implERNS_18TensorIteratorBaseERKN3c106ScalarES8_ENKUlvE_clEvENKUlvE14_clEvEUlNS5_4HalfEE_NS_6detail5ArrayIPcLi2EEEEEviT0_T1_
                    0.02%  17.074ms        20  853.70us  560.95us  1.1500ms  _ZN2at6native13reduce_kernelILi512ELi1ENS0_8ReduceOpIN3c104HalfENS0_14func_wrapper_tIS4_ZNS0_11sum_functorIS4_fS4_EclERNS_14TensorIteratorEEUlffE_EEjS4_Li4EEEEEvT1_
                    0.02%  15.527ms        10  1.5527ms  1.5357ms  1.5607ms  hgemm_32x32x32_TN
                    0.02%  14.456ms       636  22.729us  2.3680us  83.199us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<float, float, float, at::native::MulFunctor<float>>, at::detail::Array<char*, int=2>>(int, float, float)
                    0.02%  14.091ms       482  29.234us  3.1990us  95.039us  void at::native::unrolled_elementwise_kernel<at::native::BinaryFunctor<float, float, float, at::native::MulFunctor<float>>, at::detail::Array<char*, int=3>, OffsetCalculator<int=2, unsigned int, bool=0>, OffsetCalculator<int=1, unsigned int, bool=0>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, float, float, float, float, at::native::MulFunctor<float>, at::native::BinaryFunctor<float, float, float, at::native::MulFunctor<float>>)
                    0.01%  13.395ms        10  1.3395ms  1.3334ms  1.3425ms  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_24hardtanh_backward_kernelERNS_14TensorIteratorERKN3c106ScalarES7_ENKUlvE_clEvENKUlvE4_clEvEUlNS4_4HalfESA_E_NS_6detail5ArrayIPcLi3EEEEEviT0_T1_
                    0.01%  10.956ms       600  18.259us  4.0000us  51.487us  void at::native::reduce_kernel<int=512, int=1, at::native::ReduceOp<float, at::native::NormTwoOps<float, float>, unsigned int, float, int=4>>(float)
                    0.01%  10.761ms        10  1.0761ms  968.44us  1.2146ms  void at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_log_alpha_gpu_kernel<float, long>(float*, at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_log_alpha_gpu_kernel<float, long> const *, long const *, long, long const *, long const , long, float, long, long, long, long, long, long, long const , long, long, long)
                    0.01%  8.0583ms        50  161.17us  4.6070us  504.73us  void at::native::unrolled_elementwise_kernel<at::native::BinaryFunctor<float, float, float, at::native::AddFunctor<float>>, at::detail::Array<char*, int=3>, OffsetCalculator<int=2, unsigned int, bool=0>, OffsetCalculator<int=1, unsigned int, bool=0>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, float, float, float, float, at::native::AddFunctor<float>, at::native::BinaryFunctor<float, float, float, at::native::AddFunctor<float>>)
                    0.01%  7.5517ms        24  314.65us  262.40us  386.24us  void implicit_convolve_sgemm<__half, __half, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=0, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, bool, int, int)
                    0.01%  6.9596ms         4  1.7399ms  947.80us  2.6397ms  void cudnn::bn_fw_inf_1C11_kernel_NCHW<__half, float, bool=1, int=1>(float, cudnn::bn_fw_inf_1C11_kernel_NCHW<__half, float, bool=1, int=1>, cudnnTensorStruct, __half const *, float, cudnnTensorStruct*, float, cudnn::bn_fw_inf_1C11_kernel_NCHW<__half, float, bool=1, int=1> const *, cudnn::bn_fw_inf_1C11_kernel_NCHW<__half, float, bool=1, int=1> const , cudnn::bn_fw_inf_1C11_kernel_NCHW<__half, float, bool=1, int=1> const , cudnn::bn_fw_inf_1C11_kernel_NCHW<__half, float, bool=1, int=1> const , cudnn::bn_fw_inf_1C11_kernel_NCHW<__half, float, bool=1, int=1>)
                    0.01%  6.1589ms        12  513.24us  468.79us  764.34us  hgemm_32x32x32_NT_vec
                    0.01%  6.1509ms        12  512.57us  346.14us  583.16us  void at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrayBatchedCopy<c10::Half, unsigned int, int=2, int=128, int=1>(c10::Half*, at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrInputTensorMetadata<at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrayBatchedCopy<c10::Half, unsigned int, int=2, int=128, int=1>, unsigned int, int=128, int=1>, at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::TensorSizeStride<at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrInputTensorMetadata, unsigned int=4>, int, at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrInputTensorMetadata)
                    0.01%  5.6420ms        10  564.20us  516.47us  652.02us  void at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_collect_nonblank_gpu_kernel<float, long>(float*, at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_collect_nonblank_gpu_kernel<float, long> const *, long, at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_collect_nonblank_gpu_kernel<float, long> const , at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_collect_nonblank_gpu_kernel<float, long> const , at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_collect_nonblank_gpu_kernel<float, long> const , long const *, long, long const *, long const , long, at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_collect_nonblank_gpu_kernel<float, long> const , long, long, long, long, long, long, long, long, long, long, long, long, long const , long, long, long, long, bool)
                    0.00%  2.8285ms      1098  2.5760us  2.3670us  4.6720us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<long, long, long, at::native::AddFunctor<long>>, at::detail::Array<char*, int=2>>(int, long, long)
                    0.00%  2.1795ms        30  72.649us  3.2960us  203.23us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_15exp_kernel_cudaERNS_18TensorIteratorBaseEENKUlvE_clEvENKUlvE2_clEvEUlfE_NS_6detail5ArrayIPcLi2EEEEEviT0_T1_
                    0.00%  1.4605ms        10  146.05us  138.78us  154.17us  void at::native::reduce_kernel<int=512, int=1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::MaxNanFunctor<float>>, unsigned int, float, int=4>>(float)
                    0.00%  1.4527ms        30  48.422us  4.2890us  143.42us  _ZN2at6native13reduce_kernelILi512ELi1ENS0_8ReduceOpIfNS0_14func_wrapper_tIfZNS0_11sum_functorIfffEclERNS_14TensorIteratorEEUlffE_EEjfLi4EEEEEvT1_
                    0.00%  1.2516ms       512  2.4440us  2.3670us  4.9280us  void at::native::unrolled_elementwise_kernel<at::native::BinaryFunctor<int, int, int, at::native::AddFunctor<int>>, at::detail::Array<char*, int=3>, TrivialOffsetCalculator<int=2, unsigned int>, TrivialOffsetCalculator<int=1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, int, int, int, int, at::native::AddFunctor<int>, at::native::BinaryFunctor<int, int, int, at::native::AddFunctor<int>>)
                    0.00%  1.1907ms        10  119.07us  102.46us  142.94us  void at::native::reduce_kernel<int=512, int=1, at::native::ReduceOp<float, at::native::MaxOps<float>, unsigned int, float, int=4>>(float)
                    0.00%  637.40us       256  2.4890us  2.3990us  3.5200us  void at::native::vectorized_elementwise_kernel<int=2, at::native::BinaryFunctor<int, int, int, at::native::AddFunctor<int>>, at::detail::Array<char*, int=3>>(int, int, int)
                    0.00%  606.23us       240  2.5250us  2.3990us  3.4240us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BinaryFunctor<int, int, int, at::native::AddFunctor<int>>, at::detail::Array<char*, int=3>>(int, int, int)
                    0.00%  592.06us        30  19.735us  3.2320us  51.007us  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_84_GLOBAL__N__60_tmpxft_00012309_00000000_14_TensorCompare_compute_86_cpp1_ii_d0af11f717where_kernel_implERNS_14TensorIteratorEN3c1010ScalarTypeEENKUlvE_clEvENKUlvE6_clEvEUlbffE_NS_6detail5ArrayIPcLi4EEE16OffsetCalculatorILi3EjLb0EESE_ILi1EjLb0EENS0_6memory15LoadWithoutCastENSH_16StoreWithoutCastEEEviT_T0_T1_T2_T3_T4_
                    0.00%  515.36us        12  42.946us  39.647us  48.255us  void fft2d_r2c_32x32<__half, bool=0, unsigned int=1, bool=1>(float2*, __half const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)
                    0.00%  448.76us        10  44.876us  39.359us  50.207us  void fft2d_r2c_32x32<__half, bool=0, unsigned int=1, bool=0>(float2*, __half const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)
                    0.00%  383.67us        10  38.367us  37.983us  39.071us  void _GLOBAL__N__54_tmpxft_000120b7_00000000_14_SoftMax_compute_86_cpp1_ii_9f978f63::softmax_warp_forward<c10::Half, float, float, int=5, bool=1>(float*, c10::Half const *, int, int, int)
                    0.00%  382.91us        10  38.290us  35.392us  40.639us  void at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_zero_padded_gradients<float>(float*, long const *, long, long, long, long, long, long)
                    0.00%  378.23us        10  37.823us  37.600us  38.111us  void at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrayBatchedCopy<float, unsigned int, int=1, int=128, int=1>(float*, at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrInputTensorMetadata<at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrayBatchedCopy<float, unsigned int, int=1, int=128, int=1>, unsigned int, int=128, int=1>, at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::TensorSizeStride<at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrInputTensorMetadata, unsigned int=4>, int, at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrInputTensorMetadata)
                    0.00%  347.33us       323  1.0750us     799ns  6.1430us  [CUDA memset]
                    0.00%  313.95us        10  31.394us  30.975us  31.968us  void _GLOBAL__N__54_tmpxft_000120b7_00000000_14_SoftMax_compute_86_cpp1_ii_9f978f63::softmax_warp_backward<float, c10::Half, float, int=5, bool=1>(c10::Half*, float const *, float const , int, int, int)
                    0.00%  284.83us       101  2.8200us  2.2710us  3.6800us  void at::native::vectorized_elementwise_kernel<int=4, at::native::FillFunctor<int>, at::detail::Array<char*, int=1>>(int, int, at::native::FillFunctor<int>)
                    0.00%  211.17us        50  4.2230us  3.7120us  5.4720us  _ZN2at6native84_GLOBAL__N__60_tmpxft_000119e1_00000000_14_Normalization_compute_86_cpp1_ii_5c38458745unrolled_elementwise_kernel_for_multi_outputsILi3EZZZNS1_34batch_norm_update_stats_and_invertERKNS_6TensorES5_S5_S5_ddlENKUlvE_clEvENKUlvE2_clEvEUlffffE_NS_6detail5ArrayIPcLi7EEE23TrivialOffsetCalculatorILi4EjESD_ILi3EjEEEviT0_T1_T2_T3_
                    0.00%  101.79us         2  50.895us  45.184us  56.607us  void _GLOBAL__N__54_tmpxft_000120b7_00000000_14_SoftMax_compute_86_cpp1_ii_9f978f63::softmax_warp_forward<c10::Half, float, float, int=5, bool=0>(float*, c10::Half const *, int, int, int)
                    0.00%  100.51us        30  3.3500us  3.0070us  4.0320us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<float, float, bool, at::native::CompareEqFunctor<float>>, at::detail::Array<char*, int=2>>(int, float, float)
                    0.00%  68.958us        12  5.7460us  5.3440us  7.1040us  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE1_clEvENKUlvE8_clEvEUliE_NS_6detail5ArrayIPcLi2EEE23TrivialOffsetCalculatorILi1EjESC_NS0_6memory12LoadWithCastILi1EEENSD_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_
                    0.00%  64.800us        12  5.4000us  2.9120us  5.9530us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BinaryFunctor<float, float, float, at::native::DivFunctor<float>>, at::detail::Array<char*, int=3>>(int, float, float)
                    0.00%  59.553us        20  2.9770us  2.5590us  3.4570us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BinaryFunctor<float, float, float, at::native::MulFunctor<float>>, at::detail::Array<char*, int=3>>(int, float, float)
                    0.00%  58.271us        10  5.8270us  5.6000us  5.9840us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_15log_kernel_cudaERNS_18TensorIteratorBaseEENKUlvE_clEvENKUlvE2_clEvEUlfE_NS_6detail5ArrayIPcLi2EEEEEviT0_T1_
                    0.00%  55.232us        12  4.6020us  4.2240us  5.7600us  void cudnn::cnn::kern_precompute_indices<bool=0>(int*, int, int, int, int, int, int)
                    0.00%  52.672us        10  5.2670us  5.0240us  5.4720us  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE1_clEvENKUlvE4_clEvEUldE_NS_6detail5ArrayIPcLi2EEE23TrivialOffsetCalculatorILi1EjESC_NS0_6memory12LoadWithCastILi1EEENSD_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_
                    0.00%  50.624us        10  5.0620us  4.6720us  5.5040us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_22reciprocal_kernel_cudaERNS_18TensorIteratorBaseEENKUlvE_clEvENKUlvE0_clEvEUldE_NS_6detail5ArrayIPcLi2EEEEEviT0_T1_
                    0.00%  46.911us        10  4.6910us  4.5440us  4.8640us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_16sqrt_kernel_cudaERNS_18TensorIteratorBaseEENKUlvE_clEvENKUlvE2_clEvEUlfE_NS_6detail5ArrayIPcLi2EEEEEviT0_T1_
                    0.00%  45.471us         8  5.6830us  3.7430us  10.432us  _ZN2at6native13reduce_kernelILi512ELi1ENS0_8ReduceOpIlNS0_14func_wrapper_tIlZNS0_11sum_functorIlllEclERNS_14TensorIteratorEEUlllE_EEjlLi4EEEEEvT1_
                    0.00%  44.445us        16  2.7770us  2.4000us  3.9680us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<int, int, int, at::native::AddFunctor<int>>, at::detail::Array<char*, int=2>>(int, int, int)
                    0.00%  40.159us        10  4.0150us  3.8080us  4.3840us  void at::native::vectorized_elementwise_kernel<int=4, at::native::AbsFunctor<float>, at::detail::Array<char*, int=2>>(int, float, at::native::AbsFunctor<float>)
                    0.00%  34.785us        10  3.4780us  3.1360us  3.6800us  at::native::amp_update_scale_cuda_kernel(float*, int*, float*, double, double, int)
                    0.00%  34.239us        10  3.4230us  3.2640us  3.8400us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_84_GLOBAL__N__60_tmpxft_000119e1_00000000_14_Normalization_compute_86_cpp1_ii_5c38458722batch_norm_calc_invstdERKNS_6TensorES5_dENKUlvE_clEvENKUlvE2_clEvEUlfE_NS_6detail5ArrayIPcLi2EEEEEviT0_T1_
                    0.00%  33.695us        10  3.3690us  3.1680us  3.5200us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_79_GLOBAL__N__55_tmpxft_000115da_00000000_14_Indexing_compute_86_cpp1_ii_ccf5656718masked_fill_kernelIbEEvRNS_14TensorIteratorERKN3c106ScalarEENKUlvE_clEvENKUlvE6_clEvEUlfbE_NS_6detail5ArrayIPcLi3EEEEEviT0_T1_
                    0.00%  32.991us        10  3.2990us  3.2310us  3.4240us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<float, float, bool, at::native::CompareLTFunctor<float>>, at::detail::Array<char*, int=2>>(int, float, float)
                    0.00%  31.327us         8  3.9150us  3.0720us  6.3360us  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_22reciprocal_kernel_cudaERNS_18TensorIteratorBaseEENKUlvE_clEvENKUlvE2_clEvEUlfE_NS_6detail5ArrayIPcLi2EEE23TrivialOffsetCalculatorILi1EjESC_NS0_6memory12LoadWithCastILi1EEENSD_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_
                    0.00%  30.303us        10  3.0300us  2.9120us  3.1670us  _ZN2at6native29vectorized_elementwise_kernelILi4EZNS0_86_GLOBAL__N__56_tmpxft_00011ac0_00000000_14_PowKernel_compute_86_cpp1_ii_0aea0a57_7240729pow_tensor_scalar_kernel_implIffEEvRNS_18TensorIteratorBaseET0_EUlfE_NS_6detail5ArrayIPcLi2EEEEEviS6_T1_
                    0.00%  30.145us         4  7.5360us  4.2890us  10.784us  void at::native::reduce_kernel<int=512, int=1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, int=4>>(float)
                    0.00%  29.984us        10  2.9980us  2.9120us  3.1040us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<float, float, float, at::native::AddFunctor<float>>, at::detail::Array<char*, int=2>>(int, float, float)
                    0.00%  23.552us         9  2.6160us  2.2400us  3.8400us  void at::native::vectorized_elementwise_kernel<int=4, at::native::FillFunctor<long>, at::detail::Array<char*, int=1>>(int, long, at::native::FillFunctor<long>)
                    0.00%  10.655us         3  3.5510us  2.4310us  4.9920us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<long, long, bool, at::native::CompareEqFunctor<long>>, at::detail::Array<char*, int=2>>(int, long, long)
                    0.00%  10.080us         3  3.3600us  2.4000us  4.3520us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<long, long, bool, at::native::CompareGTFunctor<long>>, at::detail::Array<char*, int=2>>(int, long, long)
                    0.00%  7.5840us         2  3.7920us  2.7520us  4.8320us  void at::native::unrolled_elementwise_kernel<at::native::BUnaryFunctor<float, float, float, at::native::MulFunctor<float>>, at::detail::Array<char*, int=2>, TrivialOffsetCalculator<int=1, unsigned int>, TrivialOffsetCalculator<int=1, unsigned int>, at::native::memory::LoadWithCast<int=1>, at::native::memory::StoreWithCast>(int, float, float, float, float, at::native::MulFunctor<float>, at::native::BUnaryFunctor<float, float, float, at::native::MulFunctor<float>>)
      API calls:   51.65%  31.5613s    420151  75.118us  3.7100us  169.38ms  cudaLaunchKernel
                   27.55%  16.8344s    551154  30.543us  4.6390us  175.73ms  cudaMemcpyAsync
                   13.75%  8.40052s    487608  17.228us  1.1510us  723.27ms  cudaStreamSynchronize
                    2.58%  1.57700s   3787631     416ns     283ns  3.9906ms  cudaGetDevice
                    1.46%  889.13ms      3485  255.13us  6.1200us  96.625ms  cudaMemcpy2DAsync
                    1.11%  681.10ms   1176390     578ns     437ns  2.3994ms  cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
                    1.01%  619.74ms        70  8.8535ms  1.5250us  199.88ms  cudaFree
                    0.22%  133.49ms    155431     858ns     529ns  545.11us  cudaEventRecord
                    0.17%  101.93ms    152815     667ns     454ns  3.4522ms  cudaEventCreateWithFlags
                    0.16%  95.831ms    403219     237ns     129ns  1.0208ms  cudaGetLastError
                    0.15%  90.877ms    152738     594ns     437ns  2.3972ms  cudaEventDestroy
                    0.07%  42.143ms       148  284.75us  2.9760us  3.9399ms  cudaMalloc
                    0.05%  32.560ms     27909  1.1660us     640ns  459.71us  cudaStreamWaitEvent
                    0.03%  18.912ms        35  540.35us  4.9210us  1.7369ms  cudaHostAlloc
                    0.01%  4.8414ms      2251  2.1500us  1.9960us  20.075us  cudaFuncGetAttributes
                    0.01%  3.8888ms       323  12.039us  2.6190us  100.57us  cudaMemsetAsync
                    0.01%  3.6514ms       568  6.4280us  2.3210us  50.861us  cudaStreamDestroy
                    0.01%  3.6383ms      1252  2.9060us     875ns  25.348us  cudaEventQuery
                    0.00%  2.5120ms      4234     593ns     331ns  12.972us  cudaSetDevice
                    0.00%  2.2881ms       272  8.4120us  1.8360us  253.24us  cudaStreamCreateWithPriority
                    0.00%  1.9263ms       300  6.4210us  1.9500us  60.535us  cudaStreamCreate
                    0.00%  1.7260ms      1017  1.6970us     462ns  44.784us  cudaStreamIsCapturing
                    0.00%  838.11us       946     885ns     574ns  2.8700us  cudaStreamGetCaptureInfo
                    0.00%  733.85us        84  8.7360us  2.3360us  131.78us  cudaStreamCreateWithFlags
                    0.00%  730.92us        22  33.223us  5.5920us  454.56us  cudaDeviceSynchronize
                    0.00%  485.83us       392  1.2390us     127ns  57.884us  cuDeviceGetAttribute
                    0.00%  417.98us       240  1.7410us     527ns  16.343us  cudaPointerGetAttributes
                    0.00%  305.65us         2  152.82us  128.28us  177.36us  cudaGetDeviceProperties
                    0.00%  257.38us        34  7.5700us  6.2760us  21.314us  cudaMemcpy
                    0.00%  237.34us       730     325ns     138ns  26.566us  cuGetProcAddress
                    0.00%  157.90us        22  7.1770us  3.6470us  26.801us  cudaEventCreate
                    0.00%  69.823us         4  17.455us  11.604us  26.329us  cuDeviceGetName
                    0.00%  64.768us        28  2.3130us     168ns  17.874us  cuDevicePrimaryCtxGetState
                    0.00%  30.749us        54     569ns     294ns  3.1730us  cudaDeviceGetAttribute
                    0.00%  13.003us         1  13.003us  13.003us  13.003us  cudaDeviceGetPCIBusId
                    0.00%  11.120us         2  5.5600us  4.5000us  6.6200us  cudaEventSynchronize
                    0.00%  5.7200us         2  2.8600us  2.8010us  2.9190us  cuInit
                    0.00%  3.4790us         2  1.7390us  1.2430us  2.2360us  cudaHostGetDevicePointer
                    0.00%  3.4170us         2  1.7080us  1.5010us  1.9160us  cudaDeviceGetStreamPriorityRange
                    0.00%  1.9940us         3     664ns     242ns  1.4920us  cuDeviceGetCount
                    0.00%  1.6670us         3     555ns     400ns     787ns  cudaDriverGetVersion
                    0.00%  1.4580us         4     364ns     288ns     462ns  cuDeviceTotalMem
                    0.00%  1.3470us         4     336ns     284ns     472ns  cuDeviceGet
                    0.00%  1.0750us         1  1.0750us  1.0750us  1.0750us  cudaGetSymbolAddress
                    0.00%     931ns         4     232ns     194ns     268ns  cuDeviceGetUuid
                    0.00%     815ns         2     407ns     407ns     408ns  cudaGetDeviceCount
                    0.00%     500ns         2     250ns     224ns     276ns  cuDriverGetVersion

==11140== NVTX result:
==11140==   Thread "<unnamed>" (id = 1333417728)
==11140==     Domain "NCCL"
==11140==       Range "ncclGroupEnd"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  4.6433ms       590  7.8700us  5.5260us  499.85us  ncclGroupEnd
No kernels were profiled in this range.
No API activities were profiled in this range.

==11140==       Range "ncclGroupStart"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  1.2094ms       590  2.0490us  1.4010us  36.557us  ncclGroupStart
No kernels were profiled in this range.
No API activities were profiled in this range.

==11140==       Range "ncclReduce"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  488.77us       590     828ns     525ns  36.270us  ncclReduce
No kernels were profiled in this range.
No API activities were profiled in this range.

==11140==   Thread "<unnamed>" (id = 2300780736)
==11140==     Domain "NCCL"
==11140==       Range "ncclAllGather"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  6.6470us         9     738ns     682ns     903ns  ncclAllGather
No kernels were profiled in this range.
No API activities were profiled in this range.

==11140==       Range "ncclAllReduce"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  132.94us        49  2.7130us     521ns  36.340us  ncclAllReduce
No kernels were profiled in this range.
No API activities were profiled in this range.

==11140==       Range "ncclBroadcast"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  252.50us       298     847ns     459ns  17.309us  ncclBroadcast
No kernels were profiled in this range.
No API activities were profiled in this range.

==11140==       Range "ncclCommInitRank"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  5.8650us         1  5.8650us  5.8650us  5.8650us  ncclCommInitRank
No kernels were profiled in this range.
No API activities were profiled in this range.

==11140==       Range "ncclGroupEnd"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  29.932ms       357  83.843us  4.5450us  26.733ms  ncclGroupEnd
 GPU activities:  100.00%  25.698us         9  2.8550us  2.5280us  3.4880us  [CUDA memcpy DtoD]
      API calls:  100.00%  210.89us         9  23.432us  16.400us  38.848us  cudaMemcpyAsync

==11140==       Range "ncclGroupStart"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  904.13us       357  2.5320us  1.2470us  44.393us  ncclGroupStart
No kernels were profiled in this range.
No API activities were profiled in this range.

