==7718== NVPROF is profiling process 7718, command: python train.py +configs=librispeech
==7718== Warning: Profiling results might be incorrect with current version of nvcc compiler used to compile cuda app. Compile with nvcc compiler 9.0 or later version to get correct profiling results. Ignore this warning if code is already compiled with the recommended nvcc version 
==7718== Profiling application: python train.py +configs=librispeech
==7718== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   76.95%  50.0125s    186615  268.00us  101.15us  564.06us  maxwell_fp16_sgemm_fp16_128x32_nn
                    7.11%  4.62235s      3290  1.4050ms  67.807us  31.018ms  maxwell_fp16_sgemm_fp16_32x128_nt
                    3.72%  2.41999s       130  18.615ms  413.95us  27.899ms  maxwell_fp16_sgemm_fp16_32x128_nn
                    2.04%  1.32414s        20  66.207ms  15.566ms  117.30ms  void wgrad_alg0_engine<__half, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, int=512>(int, int, int, __half const *, int, __half*, __half const *, kernel_grad_params, __int64, int, float, int, int, int, int)
                    1.29%  838.58ms     52498  15.973us  2.3680us  778.39us  [CUDA memcpy DtoD]
                    1.05%  679.58ms     96350  7.0530us  3.7760us  17.760us  void elemWiseRNNcell<__half, __half, float, cudnnRNNMode_t=2, cudnnRNNBiasMode_t=2>(int, int, int, int, int, bool, __half const *, __half const *, __half const *, __half const *, __half const *, __half const *, __half const *, __half*, __half*, __half*, __half*, __half*, cudnnRNNClipMode_t, cudnnNanPropagation_t, float, float)
                    0.93%  605.76ms      1500  403.84us  367.74us  440.86us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::AddFunctor<float>>, at::detail::Array<char*, int=3>>(int, c10::Half, c10::Half)
                    0.89%  575.23ms    245952  2.3380us     959ns  11.960ms  [CUDA memcpy DtoH]
                    0.87%  567.66ms       338  1.6795ms     863ns  15.399ms  [CUDA memcpy HtoD]
                    0.78%  507.09ms     74580  6.7990us  3.0720us  21.088us  void LSTM_elementWise_bp1<__half, __half, float>(int, int, __half*, __half*, __half*, __half*, __half*, __half*, __half*, __half*, __half*, int, int, cudnnRNNClipMode_t, cudnnNanPropagation_t, float, float)
                    0.66%  431.59ms      3354  128.68us  2.5290us  528.63us  void at::native::vectorized_elementwise_kernel<int=4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, int=1>>(int, c10::Half, at::native::FillFunctor<c10::Half>)
                    0.46%  296.18ms      1510  196.15us  82.527us  1.8310ms  void gemmk1_kernel<float, int=256, int=5, bool=0, bool=0, bool=1, bool=0, cublasGemvTensorStridedBatched<__half const >, cublasGemvTensorStridedBatched<__half const >, cublasGemvTensorStridedBatched<__half>, float, bool=1, bool=1>(cublasGemmk1Params<float, __half const , cublasGemvTensorStridedBatched<__half const >, cublasGemvTensorStridedBatched<__half const >, __half, biasType<cublasGemvTensorStridedBatched<__half const >::value_type, __half>::type>)
                    0.43%  278.99ms      5530  50.449us  33.535us  71.518us  maxwell_gcgemm_32x32_nt
                    0.28%  183.36ms      4716  38.881us  4.1920us  4.8357ms  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE1_clEvENKUlvE18_clEvEUlN3c104HalfEE_NS_6detail5ArrayIPcLi2EEE16OffsetCalculatorILi1EjLb0EESE_NS0_6memory15LoadWithoutCastENSF_16StoreWithoutCastEEEviT_T0_T1_T2_T3_T4_
                    0.18%  118.98ms        12  9.9152ms  8.9080ms  16.223ms  void precomputed_convolve_sgemm<__half, int=1024, int=5, int=5, int=4, int=3, int=3, int=1, bool=0>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, int*)
                    0.18%  116.62ms      3005  38.809us  26.239us  100.42us  void gemv2N_kernel<int, int, __half, __half, __half, float, int=128, int=4, int=4, int=4, int=1, bool=0, cublasGemvParams<cublasGemvTensorStridedBatched<__half const >, cublasGemvTensorStridedBatched<__half const >, cublasGemvTensorStridedBatched<__half>, float>>(__half const )
                    0.17%  112.15ms      3115  36.001us  27.136us  51.743us  void fft2d_r2c_32x32<__half, bool=0, unsigned int=0, bool=0>(float2*, __half const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)
                    0.16%  106.82ms       100  1.0682ms  599.48us  1.5683ms  void GENERIC_elementWise_bp2<__half, __half, float, int=4, cudnnRNNBiasMode_t=2>(int, int, __half*, __half*, cudnn::reduced_divisor, __half*)
                    0.16%  105.42ms        50  2.1084ms  2.0853ms  2.1209ms  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE1_clEvENKUlvE18_clEvEUlN3c104HalfEE_NS_6detail5ArrayIPcLi2EEE16OffsetCalculatorILi1EjLb0EESE_NS0_6memory12LoadWithCastILi1EEENSF_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_
                    0.15%  100.65ms      3115  32.312us  23.359us  48.831us  void fft2d_c2r_32x32<__half, bool=1, bool=0, unsigned int=0, bool=0, bool=0>(__half*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, __half*, __half*, int2, int, int)
                    0.14%  90.108ms      2415  37.311us  25.632us  54.143us  void fft2d_c2r_32x32<__half, bool=0, bool=0, unsigned int=0, bool=0, bool=0>(__half*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, __half*, __half*, int2, int, int)
                    0.12%  78.578ms      2415  32.537us  24.255us  42.335us  void fft2d_r2c_32x32<__half, bool=1, unsigned int=0, bool=0>(float2*, __half const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)
                    0.10%  62.326ms        36  1.7313ms  200.51us  3.9745ms  void implicit_convolve_sgemm<__half, __half, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=0, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, bool, int, int)
                    0.09%  59.161ms        20  2.9580ms  1.9730ms  3.9544ms  void cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1>(float, cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1>, cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1>, cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1>, cudnnTensorStruct, __half const *, float, __half const , float, cudnnTensorStruct*, cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1> const *, cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1>*, cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1> const *, cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1> const , cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1> const , cudnn::bn_bw_1C11_kernel_new<__half, float, float2, int=512, bool=1, int=1>)
                    0.09%  59.146ms        20  2.9573ms  2.8750ms  3.0229ms  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_79_GLOBAL__N__55_tmpxft_000115da_00000000_14_Indexing_compute_86_cpp1_ii_ccf5656718masked_fill_kernelIbEEvRNS_14TensorIteratorERKN3c106ScalarEENKUlvE_clEvENKUlvE20_clEvEUlNS6_4HalfEbE_NS_6detail5ArrayIPcLi3EEE16OffsetCalculatorILi2EjLb0EESI_ILi1EjLb0EENS0_6memory15LoadWithoutCastENSL_16StoreWithoutCastEEEviT_T0_T1_T2_T3_T4_
                    0.08%  53.247ms       112  475.42us  285.98us  928.92us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_79_GLOBAL__N__55_tmpxft_000115da_00000000_14_Indexing_compute_86_cpp1_ii_ccf5656718masked_fill_kernelIbEEvRNS_14TensorIteratorERKN3c106ScalarEENKUlvE_clEvENKUlvE20_clEvEUlNS6_4HalfEbE_NS_6detail5ArrayIPcLi3EEEEEviT0_T1_
                    0.07%  43.260ms        60  720.99us  659.48us  1.0979ms  _ZN2at6native13reduce_kernelILi128ELi4ENS0_8ReduceOpIN3c104HalfENS0_14func_wrapper_tIfZNS0_11sum_functorIS4_ffEclERNS_14TensorIteratorEEUlffE_EEjfLi4EEEEEvT1_
                    0.06%  40.229ms       708  56.820us  3.4870us  640.38us  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE1_clEvENKUlvE18_clEvEUlN3c104HalfEE_NS_6detail5ArrayIPcLi2EEE23TrivialOffsetCalculatorILi1EjESE_NS0_6memory12LoadWithCastILi1EEENSF_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_
                    0.06%  39.368ms        24  1.6403ms  991.03us  3.5707ms  void at::native::unrolled_elementwise_kernel<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::AddFunctor<float>>, at::detail::Array<char*, int=3>, OffsetCalculator<int=2, unsigned int, bool=0>, OffsetCalculator<int=1, unsigned int, bool=0>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, c10::Half, c10::Half, c10::Half, float, at::native::AddFunctor<float>, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::AddFunctor<float>>)
                    0.05%  34.126ms       510  66.914us  2.7840us  427.61us  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE1_clEvENKUlvE6_clEvEUlfE_NS_6detail5ArrayIPcLi2EEE23TrivialOffsetCalculatorILi1EjESC_NS0_6memory12LoadWithCastILi1EEENSD_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_
                    0.05%  31.744ms        10  3.1744ms  3.1102ms  3.2400ms  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_24hardtanh_backward_kernelERNS_14TensorIteratorERKN3c106ScalarES7_ENKUlvE_clEvENKUlvE4_clEvEUlNS4_4HalfESA_E_NS_6detail5ArrayIPcLi3EEE16OffsetCalculatorILi2EjLb0EESG_ILi1EjLb0EENS0_6memory15LoadWithoutCastENSJ_16StoreWithoutCastEEEviT_T0_T1_T2_T3_T4_
                    0.04%  28.727ms        50  574.54us  564.79us  583.29us  void at::native::batch_norm_backward_elemt_channels_last_kernel<int=4, float, float, float>(float const *, float const , float const *, float const , float const *, float const , float const , at::native::batch_norm_backward_elemt_channels_last_kernel<int=4, float, float, float>*, float const *, int, int)
                    0.04%  25.326ms        60  422.10us  383.51us  631.58us  void at::native::batch_norm_transform_input_channels_last_kernel<float, float, float, int=4>(float const *, float const , float const *, float const , float const *, float const , at::native::batch_norm_transform_input_channels_last_kernel<float, float, float, int=4>*, int, int, bool)
                    0.04%  24.083ms        20  1.2042ms  777.43us  1.6057ms  void cudnn::bn_fw_tr_1C11_kernel_NCHW<__half, float, int=512, bool=1, int=1>(cudnnTensorStruct, __half const *, cudnn::bn_fw_tr_1C11_kernel_NCHW<__half, float, int=512, bool=1, int=1>, cudnnTensorStruct*, float const *, float const , cudnnTensorStruct*, cudnnTensorStruct*, cudnnTensorStruct**, float const *, float const *, float const *, cudnnTensorStruct*, cudnnTensorStruct*)
                    0.03%  21.868ms      2232  9.7970us  3.3280us  42.431us  void at::native::unrolled_elementwise_kernel<at::native::FillFunctor<bool>, at::detail::Array<char*, int=1>, OffsetCalculator<int=0, unsigned int, bool=0>, OffsetCalculator<int=1, unsigned int, bool=0>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, bool, at::native::FillFunctor<bool>, char*, int=1, at::detail::Array<char*, int=1>, int=0)
                    0.03%  21.842ms        50  436.85us  98.718us  1.0693ms  _ZN2at6native81_GLOBAL__N__57_tmpxft_000107ea_00000000_14_AmpKernels_compute_86_cpp1_ii_3810c27325multi_tensor_apply_kernelINS1_18TensorListMetadataILi1EEENS1_14UnaryOpFunctorIfLi1ELi1ELi0EEEJZZZNS0_47_amp_foreach_non_finite_check_and_unscale_cuda_EN3c108ArrayRefINS_6TensorEEERS9_RKS9_ENKUlvE_clEvENKUlvE2_clEvEUlfE_EEEvT_T0_DpT1_
                    0.03%  21.613ms      1308  16.523us  4.1920us  113.12us  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE1_clEvENKUlvE6_clEvEUlfE_NS_6detail5ArrayIPcLi2EEE16OffsetCalculatorILi1EjLb0EESC_NS0_6memory15LoadWithoutCastENSD_16StoreWithoutCastEEEviT_T0_T1_T2_T3_T4_
                    0.03%  20.830ms       240  86.791us  45.951us  213.98us  void internal::region_transform_ABC_val<int, int=32, int=32, bool=0, internal::TransformParamsABC<float, internal::TiledMatrixStridedBatch<internal::RawData<__half const , int>, internal::Tile_Col<int, int=32>>, internal::TiledMatrixStridedBatch<internal::RawData<__half const , int>, internal::Tile_Col<int, int=32>>, internal::TiledMatrixStridedBatch<internal::RawData<__half, int>, internal::Tile_Col<int, int=32>>>>(float, internal::region_transform_ABC_val<int, int=32, int=32, bool=0, internal::TransformParamsABC<float, internal::TiledMatrixStridedBatch<internal::RawData<__half const , int>::Math, internal::Tile_Col<int, int=32>>, internal::TiledMatrixStridedBatch<internal::RawData<__half const , int>, internal::Tile_Col<int, int=32>>, internal::TiledMatrixStridedBatch<internal::RawData<__half, int>, internal::Tile_Col<int, int=32>>>>, float)
                    0.03%  19.305ms        50  386.09us  380.80us  391.00us  void at::native::batch_norm_collect_statistics_channels_last_kernel<at::native::Var, float, float, int=4>(float const *, float*, float, float const * volatile *, int*, int, int, float const *)
                    0.03%  18.685ms        50  373.70us  365.98us  387.55us  void at::native::batch_norm_backward_reduce_channels_last_kernel<int=4, float, float, float>(float const *, float const , float const *, float const , float const **, float const *, float*, float, float const * volatile *, int*, int, int)
                    0.03%  18.592ms       545  34.113us  2.5600us  120.96us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BinaryFunctor<float, float, float, at::native::AddFunctor<float>>, at::detail::Array<char*, int=3>>(int, float, float)
                    0.03%  17.927ms        10  1.7927ms  1.4284ms  2.2086ms  void at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_log_beta_gpu_kernel<float, long>(float*, at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_log_beta_gpu_kernel<float, long> const *, long const *, long, long const *, long const , long, long, long, long, long, long, long, long const , long, long, long)
                    0.03%  16.447ms       747  22.017us  2.1750us  632.44us  void at::native::vectorized_elementwise_kernel<int=4, at::native::FillFunctor<float>, at::detail::Array<char*, int=1>>(int, float, at::native::FillFunctor<float>)
                    0.02%  14.720ms       636  23.144us  2.4000us  83.871us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<float, float, float, at::native::MulFunctor<float>>, at::detail::Array<char*, int=2>>(int, float, float)
                    0.02%  14.150ms       482  29.357us  3.1990us  97.119us  void at::native::unrolled_elementwise_kernel<at::native::BinaryFunctor<float, float, float, at::native::MulFunctor<float>>, at::detail::Array<char*, int=3>, OffsetCalculator<int=2, unsigned int, bool=0>, OffsetCalculator<int=1, unsigned int, bool=0>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, float, float, float, float, at::native::MulFunctor<float>, at::native::BinaryFunctor<float, float, float, at::native::MulFunctor<float>>)
                    0.02%  14.086ms        50  281.73us  246.46us  371.55us  void RNN_bidirectional_accum_bp1_1<__half, __half, float>(__half*, __half*, __half*, int)
                    0.02%  13.155ms        48  274.06us  175.13us  318.84us  void at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrayBatchedCopy<float, unsigned int, int=2, int=128, int=1>(float*, at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrInputTensorMetadata<at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrayBatchedCopy<float, unsigned int, int=2, int=128, int=1>, unsigned int, int=128, int=1>, at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::TensorSizeStride<at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrInputTensorMetadata, unsigned int=4>, int, at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrInputTensorMetadata)
                    0.02%  10.972ms       600  18.286us  4.1280us  51.231us  void at::native::reduce_kernel<int=512, int=1, at::native::ReduceOp<float, at::native::NormTwoOps<float, float>, unsigned int, float, int=4>>(float)
                    0.02%  9.9473ms        10  994.73us  861.68us  1.1482ms  void at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_log_alpha_gpu_kernel<float, long>(float*, at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_log_alpha_gpu_kernel<float, long> const *, long const *, long, long const *, long const , long, float, long, long, long, long, long, long, long const , long, long, long)
                    0.01%  9.2217ms        20  461.09us  299.58us  677.85us  _ZN2at6native13reduce_kernelILi512ELi1ENS0_8ReduceOpIN3c104HalfENS0_14func_wrapper_tIS4_ZNS0_11sum_functorIS4_fS4_EclERNS_14TensorIteratorEEUlffE_EEjS4_Li4EEEEEvT1_
                    0.01%  8.9740ms        24  373.92us  231.36us  758.84us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_84_GLOBAL__N__60_tmpxft_00012309_00000000_14_TensorCompare_compute_86_cpp1_ii_d0af11f724clamp_scalar_kernel_implERNS_18TensorIteratorBaseERKN3c106ScalarES8_ENKUlvE_clEvENKUlvE14_clEvEUlNS5_4HalfEE_NS_6detail5ArrayIPcLi2EEEEEviT0_T1_
                    0.01%  7.8231ms        10  782.31us  773.59us  790.68us  hgemm_32x32x32_TN
                    0.01%  6.6921ms        10  669.21us  662.01us  673.21us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_24hardtanh_backward_kernelERNS_14TensorIteratorERKN3c106ScalarES7_ENKUlvE_clEvENKUlvE4_clEvEUlNS4_4HalfESA_E_NS_6detail5ArrayIPcLi3EEEEEviT0_T1_
                    0.01%  5.3377ms        10  533.77us  443.03us  660.09us  void at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_collect_nonblank_gpu_kernel<float, long>(float*, at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_collect_nonblank_gpu_kernel<float, long> const *, long, at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_collect_nonblank_gpu_kernel<float, long> const , at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_collect_nonblank_gpu_kernel<float, long> const , at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_collect_nonblank_gpu_kernel<float, long> const , long const *, long, long const *, long const , long, at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_backward_collect_nonblank_gpu_kernel<float, long> const , long, long, long, long, long, long, long, long, long, long, long, long, long const , long, long, long, long, bool)
                    0.01%  4.0140ms        50  80.280us  4.5760us  254.11us  void at::native::unrolled_elementwise_kernel<at::native::BinaryFunctor<float, float, float, at::native::AddFunctor<float>>, at::detail::Array<char*, int=3>, OffsetCalculator<int=2, unsigned int, bool=0>, OffsetCalculator<int=1, unsigned int, bool=0>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, float, float, float, float, at::native::AddFunctor<float>, at::native::BinaryFunctor<float, float, float, at::native::AddFunctor<float>>)
                    0.01%  3.4943ms         4  873.58us  485.08us  1.3343ms  void cudnn::bn_fw_inf_1C11_kernel_NCHW<__half, float, bool=1, int=1>(float, cudnn::bn_fw_inf_1C11_kernel_NCHW<__half, float, bool=1, int=1>, cudnnTensorStruct, __half const *, float, cudnnTensorStruct*, float, cudnn::bn_fw_inf_1C11_kernel_NCHW<__half, float, bool=1, int=1> const *, cudnn::bn_fw_inf_1C11_kernel_NCHW<__half, float, bool=1, int=1> const , cudnn::bn_fw_inf_1C11_kernel_NCHW<__half, float, bool=1, int=1> const , cudnn::bn_fw_inf_1C11_kernel_NCHW<__half, float, bool=1, int=1> const , cudnn::bn_fw_inf_1C11_kernel_NCHW<__half, float, bool=1, int=1>)
                    0.00%  3.2169ms        12  268.08us  247.58us  396.57us  hgemm_32x32x32_NT_vec
                    0.00%  3.1732ms        12  264.43us  243.55us  281.85us  void implicit_convolve_sgemm<__half, __half, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=0, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, bool, int, int)
                    0.00%  3.1583ms        12  263.19us  195.71us  295.58us  void at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrayBatchedCopy<c10::Half, unsigned int, int=2, int=128, int=1>(c10::Half*, at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrInputTensorMetadata<at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrayBatchedCopy<c10::Half, unsigned int, int=2, int=128, int=1>, unsigned int, int=128, int=1>, at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::TensorSizeStride<at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrInputTensorMetadata, unsigned int=4>, int, at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrInputTensorMetadata)
                    0.00%  1.5308ms       586  2.6120us  2.3670us  4.7360us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<long, long, long, at::native::AddFunctor<long>>, at::detail::Array<char*, int=2>>(int, long, long)
                    0.00%  1.0961ms        30  36.535us  2.6890us  101.37us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_15exp_kernel_cudaERNS_18TensorIteratorBaseEENKUlvE_clEvENKUlvE2_clEvEUlfE_NS_6detail5ArrayIPcLi2EEEEEviT0_T1_
                    0.00%  855.19us        30  28.506us  3.9990us  79.742us  _ZN2at6native13reduce_kernelILi512ELi1ENS0_8ReduceOpIfNS0_14func_wrapper_tIfZNS0_11sum_functorIfffEclERNS_14TensorIteratorEEUlffE_EEjfLi4EEEEEvT1_
                    0.00%  778.77us        10  77.877us  69.279us  84.031us  void at::native::reduce_kernel<int=512, int=1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::MaxNanFunctor<float>>, unsigned int, float, int=4>>(float)
                    0.00%  614.36us       256  2.3990us  2.3670us  3.1360us  void at::native::unrolled_elementwise_kernel<at::native::BinaryFunctor<int, int, int, at::native::AddFunctor<int>>, at::detail::Array<char*, int=3>, TrivialOffsetCalculator<int=2, unsigned int>, TrivialOffsetCalculator<int=1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, int, int, int, int, at::native::AddFunctor<int>, at::native::BinaryFunctor<int, int, int, at::native::AddFunctor<int>>)
                    0.00%  603.83us        10  60.383us  53.503us  69.631us  void at::native::reduce_kernel<int=512, int=1, at::native::ReduceOp<float, at::native::MaxOps<float>, unsigned int, float, int=4>>(float)
                    0.00%  505.34us        12  42.111us  40.032us  44.736us  void fft2d_r2c_32x32<__half, bool=0, unsigned int=1, bool=1>(float2*, __half const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)
                    0.00%  430.59us        10  43.058us  39.488us  46.879us  void fft2d_r2c_32x32<__half, bool=0, unsigned int=1, bool=0>(float2*, __half const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)
                    0.00%  378.20us        10  37.820us  37.600us  38.176us  void at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrayBatchedCopy<float, unsigned int, int=1, int=128, int=1>(float*, at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrInputTensorMetadata<at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrayBatchedCopy<float, unsigned int, int=1, int=128, int=1>, unsigned int, int=128, int=1>, at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::TensorSizeStride<at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrInputTensorMetadata, unsigned int=4>, int, at::native::_GLOBAL__N__52_tmpxft_000120a5_00000000_14_Shape_compute_86_cpp1_ii_cedd8df2::CatArrInputTensorMetadata)
                    0.00%  362.81us        30  12.093us  3.2000us  28.448us  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_84_GLOBAL__N__60_tmpxft_00012309_00000000_14_TensorCompare_compute_86_cpp1_ii_d0af11f717where_kernel_implERNS_14TensorIteratorEN3c1010ScalarTypeEENKUlvE_clEvENKUlvE6_clEvEUlbffE_NS_6detail5ArrayIPcLi4EEE16OffsetCalculatorILi3EjLb0EESE_ILi1EjLb0EENS0_6memory15LoadWithoutCastENSH_16StoreWithoutCastEEEviT_T0_T1_T2_T3_T4_
                    0.00%  353.73us       323  1.0950us     800ns  7.5200us  [CUDA memset]
                    0.00%  319.61us       128  2.4960us  2.3990us  8.6400us  void at::native::vectorized_elementwise_kernel<int=2, at::native::BinaryFunctor<int, int, int, at::native::AddFunctor<int>>, at::detail::Array<char*, int=3>>(int, int, int)
                    0.00%  316.83us       101  3.1360us  2.2710us  5.7910us  void at::native::vectorized_elementwise_kernel<int=4, at::native::FillFunctor<int>, at::detail::Array<char*, int=1>>(int, int, at::native::FillFunctor<int>)
                    0.00%  304.83us        10  30.482us  28.192us  32.575us  void at::native::_GLOBAL__N__54_tmpxft_0001171a_00000000_14_LossCTC_compute_86_cpp1_ii_88d8892b::ctc_loss_zero_padded_gradients<float>(float*, long const *, long, long, long, long, long, long)
                    0.00%  279.74us       112  2.4970us  2.4000us  3.5200us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BinaryFunctor<int, int, int, at::native::AddFunctor<int>>, at::detail::Array<char*, int=3>>(int, int, int)
                    0.00%  262.27us        50  5.2450us  4.8970us  8.3200us  _ZN2at6native84_GLOBAL__N__60_tmpxft_000119e1_00000000_14_Normalization_compute_86_cpp1_ii_5c38458745unrolled_elementwise_kernel_for_multi_outputsILi3EZZZNS1_34batch_norm_update_stats_and_invertERKNS_6TensorES5_S5_S5_ddlENKUlvE_clEvENKUlvE2_clEvEUlffffE_NS_6detail5ArrayIPcLi7EEE23TrivialOffsetCalculatorILi4EjESD_ILi3EjEEEviT0_T1_T2_T3_
                    0.00%  208.76us        10  20.876us  20.640us  21.023us  void _GLOBAL__N__54_tmpxft_000120b7_00000000_14_SoftMax_compute_86_cpp1_ii_9f978f63::softmax_warp_forward<c10::Half, float, float, int=5, bool=1>(float*, c10::Half const *, int, int, int)
                    0.00%  170.56us        10  17.055us  16.544us  17.408us  void _GLOBAL__N__54_tmpxft_000120b7_00000000_14_SoftMax_compute_86_cpp1_ii_9f978f63::softmax_warp_backward<float, c10::Half, float, int=5, bool=1>(c10::Half*, float const *, float const , int, int, int)
                    0.00%  97.981us        30  3.2660us  2.6240us  4.0630us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<float, float, bool, at::native::CompareEqFunctor<float>>, at::detail::Array<char*, int=2>>(int, float, float)
                    0.00%  63.806us        12  5.3170us  4.7030us  7.2640us  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE1_clEvENKUlvE8_clEvEUliE_NS_6detail5ArrayIPcLi2EEE23TrivialOffsetCalculatorILi1EjESC_NS0_6memory12LoadWithCastILi1EEENSD_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_
                    0.00%  59.040us        20  2.9520us  2.5590us  3.4880us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BinaryFunctor<float, float, float, at::native::MulFunctor<float>>, at::detail::Array<char*, int=3>>(int, float, float)
                    0.00%  57.534us        10  5.7530us  4.6070us  6.2400us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_15log_kernel_cudaERNS_18TensorIteratorBaseEENKUlvE_clEvENKUlvE2_clEvEUlfE_NS_6detail5ArrayIPcLi2EEEEEviT0_T1_
                    0.00%  56.863us        12  4.7380us  2.7200us  5.1200us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BinaryFunctor<float, float, float, at::native::DivFunctor<float>>, at::detail::Array<char*, int=3>>(int, float, float)
                    0.00%  53.472us         2  26.736us  23.744us  29.728us  void _GLOBAL__N__54_tmpxft_000120b7_00000000_14_SoftMax_compute_86_cpp1_ii_9f978f63::softmax_warp_forward<c10::Half, float, float, int=5, bool=0>(float*, c10::Half const *, int, int, int)
                    0.00%  51.999us        12  4.3330us  4.0640us  5.3440us  void cudnn::cnn::kern_precompute_indices<bool=0>(int*, int, int, int, int, int, int)
                    0.00%  48.962us        10  4.8960us  4.7680us  5.1200us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_22reciprocal_kernel_cudaERNS_18TensorIteratorBaseEENKUlvE_clEvENKUlvE0_clEvEUldE_NS_6detail5ArrayIPcLi2EEEEEviT0_T1_
                    0.00%  47.906us        10  4.7900us  4.6080us  5.1200us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_16sqrt_kernel_cudaERNS_18TensorIteratorBaseEENKUlvE_clEvENKUlvE2_clEvEUlfE_NS_6detail5ArrayIPcLi2EEEEEviT0_T1_
                    0.00%  47.392us        10  4.7390us  4.4480us  4.9920us  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE1_clEvENKUlvE4_clEvEUldE_NS_6detail5ArrayIPcLi2EEE23TrivialOffsetCalculatorILi1EjESC_NS0_6memory12LoadWithCastILi1EEENSD_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_
                    0.00%  45.629us         8  5.7030us  3.6800us  10.784us  _ZN2at6native13reduce_kernelILi512ELi1ENS0_8ReduceOpIlNS0_14func_wrapper_tIlZNS0_11sum_functorIlllEclERNS_14TensorIteratorEEUlllE_EEjlLi4EEEEEvT1_
                    0.00%  43.550us        16  2.7210us  2.3990us  4.0960us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<int, int, int, at::native::AddFunctor<int>>, at::detail::Array<char*, int=2>>(int, int, int)
                    0.00%  37.725us        10  3.7720us  3.5510us  4.0960us  void at::native::vectorized_elementwise_kernel<int=4, at::native::AbsFunctor<float>, at::detail::Array<char*, int=2>>(int, float, at::native::AbsFunctor<float>)
                    0.00%  35.360us        10  3.5360us  3.0080us  3.9680us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_79_GLOBAL__N__55_tmpxft_000115da_00000000_14_Indexing_compute_86_cpp1_ii_ccf5656718masked_fill_kernelIbEEvRNS_14TensorIteratorERKN3c106ScalarEENKUlvE_clEvENKUlvE6_clEvEUlfbE_NS_6detail5ArrayIPcLi3EEEEEviT0_T1_
                    0.00%  34.845us        10  3.4840us  3.2000us  3.6470us  at::native::amp_update_scale_cuda_kernel(float*, int*, float*, double, double, int)
                    0.00%  34.463us        10  3.4460us  2.9760us  4.0000us  _ZN2at6native29vectorized_elementwise_kernelILi4EZZZNS0_84_GLOBAL__N__60_tmpxft_000119e1_00000000_14_Normalization_compute_86_cpp1_ii_5c38458722batch_norm_calc_invstdERKNS_6TensorES5_dENKUlvE_clEvENKUlvE2_clEvEUlfE_NS_6detail5ArrayIPcLi2EEEEEviT0_T1_
                    0.00%  32.925us        10  3.2920us  3.1670us  3.5200us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<float, float, bool, at::native::CompareLTFunctor<float>>, at::detail::Array<char*, int=2>>(int, float, float)
                    0.00%  31.200us        10  3.1200us  2.9760us  3.2640us  _ZN2at6native29vectorized_elementwise_kernelILi4EZNS0_86_GLOBAL__N__56_tmpxft_00011ac0_00000000_14_PowKernel_compute_86_cpp1_ii_0aea0a57_7240729pow_tensor_scalar_kernel_implIffEEvRNS_18TensorIteratorBaseET0_EUlfE_NS_6detail5ArrayIPcLi2EEEEEviS6_T1_
                    0.00%  30.112us        10  3.0110us  2.9120us  3.2000us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<float, float, float, at::native::AddFunctor<float>>, at::detail::Array<char*, int=2>>(int, float, float)
                    0.00%  29.630us         8  3.7030us  3.0080us  5.4080us  _ZN2at6native27unrolled_elementwise_kernelIZZZNS0_22reciprocal_kernel_cudaERNS_18TensorIteratorBaseEENKUlvE_clEvENKUlvE2_clEvEUlfE_NS_6detail5ArrayIPcLi2EEE23TrivialOffsetCalculatorILi1EjESC_NS0_6memory12LoadWithCastILi1EEENSD_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_
                    0.00%  28.384us         4  7.0960us  4.2880us  9.8880us  void at::native::reduce_kernel<int=512, int=1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, int=4>>(float)
                    0.00%  25.184us         9  2.7980us  2.2400us  4.2560us  void at::native::vectorized_elementwise_kernel<int=4, at::native::FillFunctor<long>, at::detail::Array<char*, int=1>>(int, long, at::native::FillFunctor<long>)
                    0.00%  11.104us         3  3.7010us  2.4320us  4.9920us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<long, long, bool, at::native::CompareEqFunctor<long>>, at::detail::Array<char*, int=2>>(int, long, long)
                    0.00%  10.847us         3  3.6150us  2.4310us  4.5120us  void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<long, long, bool, at::native::CompareGTFunctor<long>>, at::detail::Array<char*, int=2>>(int, long, long)
                    0.00%  7.6170us         2  3.8080us  2.7530us  4.8640us  void at::native::unrolled_elementwise_kernel<at::native::BUnaryFunctor<float, float, float, at::native::MulFunctor<float>>, at::detail::Array<char*, int=2>, TrivialOffsetCalculator<int=1, unsigned int>, TrivialOffsetCalculator<int=1, unsigned int>, at::native::memory::LoadWithCast<int=1>, at::native::memory::StoreWithCast>(int, float, float, float, float, at::native::MulFunctor<float>, at::native::BUnaryFunctor<float, float, float, at::native::MulFunctor<float>>)
      API calls:   64.24%  24.5844s    402329  61.105us  3.6630us  136.90ms  cudaLaunchKernel
                   15.76%  6.03319s    296964  20.316us  4.6290us  81.997ms  cudaMemcpyAsync
                   13.04%  4.98885s    246268  20.257us  1.0680us  451.53ms  cudaStreamSynchronize
                    2.18%  834.97ms   1990988     419ns     287ns  2.1778ms  cudaGetDevice
                    1.90%  725.39ms   1146235     632ns     445ns  3.4288ms  cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
                    1.36%  520.93ms        57  9.1392ms  1.5910us  203.24ms  cudaFree
                    0.36%  138.19ms    154951     891ns     571ns  3.3274ms  cudaEventRecord
                    0.27%  104.34ms    152335     684ns     477ns  517.96us  cudaEventCreateWithFlags
                    0.27%  101.69ms    376828     269ns     131ns  1.9313ms  cudaGetLastError
                    0.24%  90.847ms    152258     596ns     449ns  2.2844ms  cudaEventDestroy
                    0.10%  37.271ms      1790  20.821us  6.5540us  464.72us  cudaMemcpy2DAsync
                    0.09%  33.667ms     27801  1.2110us     645ns  931.92us  cudaStreamWaitEvent
                    0.07%  27.159ms       135  201.18us  3.2590us  2.6311ms  cudaMalloc
                    0.05%  19.627ms        35  560.77us  5.7340us  1.6763ms  cudaHostAlloc
                    0.01%  4.9607ms      2251  2.2030us  1.9840us  22.169us  cudaFuncGetAttributes
                    0.01%  4.0735ms       323  12.611us  2.7120us  43.200us  cudaMemsetAsync
                    0.01%  4.0365ms      1251  3.2260us     902ns  482.15us  cudaEventQuery
                    0.01%  3.5711ms       568  6.2870us  2.2940us  92.896us  cudaStreamDestroy
                    0.01%  2.4510ms      4234     578ns     334ns  4.9260us  cudaSetDevice
                    0.01%  1.9341ms       300  6.4470us  1.8430us  50.273us  cudaStreamCreate
                    0.00%  1.8151ms       272  6.6730us  1.7220us  267.92us  cudaStreamCreateWithPriority
                    0.00%  1.5752ms      1004  1.5680us     474ns  32.203us  cudaStreamIsCapturing
                    0.00%  893.57us       946     944ns     608ns  4.1500us  cudaStreamGetCaptureInfo
                    0.00%  871.16us        84  10.370us  2.1690us  128.43us  cudaStreamCreateWithFlags
                    0.00%  702.70us        22  31.940us  5.5970us  403.96us  cudaDeviceSynchronize
                    0.00%  497.64us       392  1.2690us     128ns  61.702us  cuDeviceGetAttribute
                    0.00%  477.57us       240  1.9890us     586ns  44.935us  cudaPointerGetAttributes
                    0.00%  339.99us         2  170.00us  132.74us  207.25us  cudaGetDeviceProperties
                    0.00%  322.90us        34  9.4970us  6.3330us  79.083us  cudaMemcpy
                    0.00%  202.02us       730     276ns     143ns  2.4390us  cuGetProcAddress
                    0.00%  145.13us        22  6.5960us  3.3550us  22.871us  cudaEventCreate
                    0.00%  69.474us         4  17.368us  10.889us  27.448us  cuDeviceGetName
                    0.00%  50.258us        28  1.7940us     171ns  6.8470us  cuDevicePrimaryCtxGetState
                    0.00%  31.968us        54     592ns     300ns  3.0000us  cudaDeviceGetAttribute
                    0.00%  18.062us         3  6.0200us     217ns  17.525us  cuDeviceGetCount
                    0.00%  13.916us         1  13.916us  13.916us  13.916us  cudaDeviceGetPCIBusId
                    0.00%  12.096us         2  6.0480us  5.8310us  6.2650us  cudaEventSynchronize
                    0.00%  5.2190us         2  2.6090us  2.5720us  2.6470us  cuInit
                    0.00%  3.9870us         2  1.9930us  1.8360us  2.1510us  cudaDeviceGetStreamPriorityRange
                    0.00%  3.6030us         2  1.8010us  1.3530us  2.2500us  cudaHostGetDevicePointer
                    0.00%  3.0760us         3  1.0250us     399ns  1.9140us  cudaDriverGetVersion
                    0.00%  2.4540us         4     613ns     210ns  1.6840us  cuDeviceTotalMem
                    0.00%  1.1410us         4     285ns     209ns     374ns  cuDeviceGet
                    0.00%  1.1380us         1  1.1380us  1.1380us  1.1380us  cudaGetSymbolAddress
                    0.00%     899ns         4     224ns     203ns     246ns  cuDeviceGetUuid
                    0.00%     732ns         2     366ns     334ns     398ns  cudaGetDeviceCount
                    0.00%     429ns         2     214ns     208ns     221ns  cuDriverGetVersion

==7718== NVTX result:
==7718==   Thread "<unnamed>" (id = 430700288)
==7718==     Domain "NCCL"
==7718==       Range "ncclGroupEnd"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  4.0232ms       590  6.8190us  5.5680us  37.630us  ncclGroupEnd
No kernels were profiled in this range.
No API activities were profiled in this range.

==7718==       Range "ncclGroupStart"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  1.1335ms       590  1.9210us  1.3720us  38.733us  ncclGroupStart
No kernels were profiled in this range.
No API activities were profiled in this range.

==7718==       Range "ncclReduce"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  438.79us       590     743ns     523ns  12.212us  ncclReduce
No kernels were profiled in this range.
No API activities were profiled in this range.

==7718==   Thread "<unnamed>" (id = 1600143552)
==7718==     Domain "NCCL"
==7718==       Range "ncclAllGather"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  6.5200us         9     724ns     648ns     799ns  ncclAllGather
No kernels were profiled in this range.
No API activities were profiled in this range.

==7718==       Range "ncclAllReduce"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  145.95us        49  2.9780us     575ns  42.811us  ncclAllReduce
No kernels were profiled in this range.
No API activities were profiled in this range.

==7718==       Range "ncclBroadcast"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  216.87us       298     727ns     481ns  8.4440us  ncclBroadcast
No kernels were profiled in this range.
No API activities were profiled in this range.

==7718==       Range "ncclCommInitRank"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  5.2400us         1  5.2400us  5.2400us  5.2400us  ncclCommInitRank
No kernels were profiled in this range.
No API activities were profiled in this range.

==7718==       Range "ncclGroupEnd"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  31.455ms       357  88.108us  4.8000us  28.564ms  ncclGroupEnd
 GPU activities:  100.00%  25.472us         9  2.8300us  2.4000us  3.6480us  [CUDA memcpy DtoD]
      API calls:  100.00%  304.82us         9  33.869us  15.091us  102.66us  cudaMemcpyAsync

==7718==       Range "ncclGroupStart"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  873.35us       357  2.4460us  1.1680us  91.394us  ncclGroupStart
No kernels were profiled in this range.
No API activities were profiled in this range.

